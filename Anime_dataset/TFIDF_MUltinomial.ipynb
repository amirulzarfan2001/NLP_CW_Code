{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa80d396",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\nlp_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from my_import import *\n",
    "df_train = pd.read_csv('df_train.csv')\n",
    "df_val = pd.read_csv('df_val.csv')\n",
    "df_test = pd.read_csv('df_test.csv')\n",
    "\n",
    "#Make sure the genre collumns is in lists not strings\n",
    "#NEED TO DO THIS EVERYTIME EXPORT DATASET\n",
    "df_train['genres'] = df_train['genres'].apply(lambda x: list(ast.literal_eval(x)))\n",
    "df_val['genres'] = df_val['genres'].apply(lambda x: list(ast.literal_eval(x)))\n",
    "df_test['genres'] = df_test['genres'].apply(lambda x: list(ast.literal_eval(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86344727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 0.3128\n",
      "Adventure: 0.2180\n",
      "Comedy: 0.4091\n",
      "Drama: 0.2069\n",
      "Fantasy: 0.2368\n",
      "Historical: 0.0743\n",
      "Kids: 0.0834\n",
      "Mecha: 0.0763\n",
      "Music: 0.0514\n",
      "Mystery: 0.0666\n",
      "Romance: 0.1678\n",
      "School: 0.1360\n",
      "Sci-Fi: 0.1993\n",
      "Seinen: 0.0712\n",
      "Shoujo: 0.0565\n",
      "Shounen: 0.1603\n",
      "Slice of Life: 0.1410\n",
      "Sports: 0.0507\n",
      "Super Power: 0.0500\n",
      "Supernatural: 0.1277\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3127808988764045,\n",
       " 0.21797752808988763,\n",
       " 0.40912921348314607,\n",
       " 0.20688202247191012,\n",
       " 0.23679775280898877,\n",
       " 0.07429775280898876,\n",
       " 0.08342696629213484,\n",
       " 0.07626404494382022,\n",
       " 0.05140449438202247,\n",
       " 0.06657303370786517,\n",
       " 0.1678370786516854,\n",
       " 0.13595505617977527,\n",
       " 0.19929775280898876,\n",
       " 0.07120786516853933,\n",
       " 0.056460674157303374,\n",
       " 0.16025280898876404,\n",
       " 0.14101123595505619,\n",
       " 0.050702247191011234,\n",
       " 0.05,\n",
       " 0.12766853932584268]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generating prior probability thresholds\n",
    "# Flatten all genre lists into one long list\n",
    "all_genres = sorted(set(genre for sublist in df_train[\"genres\"] for genre in sublist))\n",
    "\n",
    "# Flatten the genre lists\n",
    "all_genres_comb = [genre for genre_list in df_train['genres'] for genre in genre_list]\n",
    "\n",
    "# Count each genre\n",
    "genre_counts = Counter(all_genres_comb)\n",
    "\n",
    "# Total number of samples\n",
    "total_samples = len(df_train)\n",
    "\n",
    "# Compute prior probability for each genre\n",
    "genre_priors = {genre: count / total_samples for genre, count in genre_counts.items()}\n",
    "\n",
    "# Display\n",
    "prior_threshold=[]\n",
    "for genre, prob in sorted(genre_priors.items()):\n",
    "    print(f\"{genre}: {prob:.4f}\")\n",
    "    prior_threshold.append(prob)\n",
    "prior_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b28b76e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef\n",
    "\n",
    "def optimize_thresholds_with_precision_constraint(probs, labels, thresholds=np.linspace(0, 1, 1000), min_precision=0.5):\n",
    "    best_thresholds = []\n",
    "    for i in range(probs.shape[1]):\n",
    "        best_f1 = 0\n",
    "        best_thresh = 0.5\n",
    "        for t in thresholds:\n",
    "            pred = (probs[:, i] >= t).astype(int)\n",
    "            precision = precision_score(labels[:, i], pred, zero_division=0)\n",
    "            f1 = f1_score(labels[:, i], pred, zero_division=0)\n",
    "            if f1 > best_f1 and precision >= min_precision:\n",
    "                best_f1 = f1\n",
    "                best_thresh = t\n",
    "        best_thresholds.append(best_thresh)\n",
    "        print(f\"Label {i}: Best threshold = {best_thresh:.2f}, F1 = {best_f1:.4f}\")\n",
    "    return (best_thresholds)\n",
    "\n",
    "def compute_tpr_tnr(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0,1]).ravel()\n",
    "    tpr = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    tnr = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "    return tpr, tnr\n",
    "\n",
    "def optimize_thresholds_with_mcc_constraint(probs, labels, thresholds=np.linspace(0, 1, 1000)):\n",
    "    best_thresholds = []\n",
    "\n",
    "    for i in range(probs.shape[1]):\n",
    "        best_mcc = -1\n",
    "        best_thresh = 0.5\n",
    "\n",
    "        for t in thresholds:\n",
    "            pred = (probs[:, i] >= t).astype(int)\n",
    "            tpr, tnr = compute_tpr_tnr(labels[:, i], pred)\n",
    "            mcc = matthews_corrcoef(labels[:, i], pred)\n",
    "            if mcc > best_mcc:\n",
    "                best_mcc = mcc\n",
    "                best_thresh = t\n",
    " \n",
    "\n",
    "        best_thresholds.append(best_thresh)\n",
    "        print(f\"Label {i}: Best threshold = {best_thresh:.2f}, MCC = {best_mcc:.4f}\")\n",
    "    \n",
    "    return best_thresholds\n",
    "\n",
    "#optimised_thresh=optimize_thresholds_with_precision_constraint(val_prob,val_labels)\n",
    "#optimised_thresh=optimize_thresholds_with_mcc_constraint(val_prob,val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bc293db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-6 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-6 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-6 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-6 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-6 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneVsRestClassifier(estimator=MultinomialNB(alpha=0.1))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneVsRestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.multiclass.OneVsRestClassifier.html\">?<span>Documentation for OneVsRestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>OneVsRestClassifier(estimator=MultinomialNB(alpha=0.1))</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>estimator: MultinomialNB</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB(alpha=0.1)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultinomialNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB(alpha=0.1)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneVsRestClassifier(estimator=MultinomialNB(alpha=0.1))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df_train['clean_synopsis'] = df_train['synopsis'].apply(clean_text)\n",
    "df_val['clean_synopsis'] = df_val['synopsis'].apply(clean_text)\n",
    "df_test['clean_synopsis'] = df_test['synopsis'].apply(clean_text)\n",
    "\n",
    "#Parameters that can be changed:\n",
    "#Number of wordds in vocublary\n",
    "#Class weighting\n",
    "\n",
    "\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "mlb=MultiLabelBinarizer()\n",
    "y_train = mlb.fit_transform(df_train['genres'])\n",
    "#display(y)\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\",max_features=10000,ngram_range=(1,4),min_df=2,max_df=0.8)\n",
    "X_train = vectorizer.fit_transform(df_train['clean_synopsis'])\n",
    "#display(X_train)\n",
    "#print(vectorizer.get_feature_names_out(),len(vectorizer.get_feature_names_out()))\n",
    "#print(X_train.toarray())\n",
    "\n",
    "y_val= mlb.transform(df_val['genres'])\n",
    "X_val = vectorizer.transform(df_val['clean_synopsis'])\n",
    "y_test= mlb.transform(df_test['genres'])\n",
    "X_test = vectorizer.transform(df_test['clean_synopsis'])\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "classifier = OneVsRestClassifier(MultinomialNB(alpha=0.1))#Already tried with balanced class but it is worse\n",
    "classifier.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cbdcc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 'Action' word frequency:\n",
      "Top 10 words with highest frequency:\n",
      "world: 1036\n",
      "new: 607\n",
      "life: 602\n",
      "year: 550\n",
      "power: 454\n",
      "friend: 442\n",
      "girl: 422\n",
      "school: 413\n",
      "human: 408\n",
      "mysterious: 401\n",
      "earth: 400\n",
      "battle: 399\n",
      "city: 383\n",
      "war: 372\n",
      "day: 362\n",
      "young: 354\n",
      "known: 349\n",
      "time: 332\n",
      "fight: 323\n",
      "story: 301\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Adventure' word frequency:\n",
      "Top 10 words with highest frequency:\n",
      "world: 824\n",
      "life: 414\n",
      "new: 410\n",
      "friend: 367\n",
      "year: 350\n",
      "power: 315\n",
      "earth: 289\n",
      "time: 282\n",
      "young: 273\n",
      "girl: 271\n",
      "mysterious: 271\n",
      "human: 256\n",
      "named: 255\n",
      "day: 242\n",
      "story: 240\n",
      "boy: 237\n",
      "way: 226\n",
      "journey: 218\n",
      "city: 215\n",
      "people: 213\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Comedy' word frequency:\n",
      "Top 10 words with highest frequency:\n",
      "school: 1015\n",
      "girl: 915\n",
      "life: 796\n",
      "world: 780\n",
      "new: 779\n",
      "friend: 683\n",
      "day: 579\n",
      "time: 498\n",
      "student: 464\n",
      "episode: 457\n",
      "high: 457\n",
      "year: 449\n",
      "story: 436\n",
      "love: 377\n",
      "high school: 375\n",
      "make: 369\n",
      "series: 366\n",
      "way: 345\n",
      "family: 325\n",
      "boy: 306\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Drama' word frequency:\n",
      "Top 10 words with highest frequency:\n",
      "life: 610\n",
      "school: 497\n",
      "girl: 470\n",
      "world: 463\n",
      "year: 422\n",
      "friend: 405\n",
      "new: 401\n",
      "day: 357\n",
      "time: 324\n",
      "young: 287\n",
      "story: 286\n",
      "high: 271\n",
      "love: 271\n",
      "human: 245\n",
      "boy: 238\n",
      "begin: 230\n",
      "earth: 220\n",
      "family: 220\n",
      "student: 220\n",
      "high school: 219\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Fantasy' word frequency:\n",
      "Top 10 words with highest frequency:\n",
      "world: 939\n",
      "life: 500\n",
      "girl: 447\n",
      "new: 431\n",
      "friend: 379\n",
      "power: 378\n",
      "year: 336\n",
      "human: 321\n",
      "day: 310\n",
      "mysterious: 295\n",
      "time: 293\n",
      "story: 286\n",
      "young: 284\n",
      "demon: 257\n",
      "named: 237\n",
      "way: 232\n",
      "people: 230\n",
      "school: 229\n",
      "game: 228\n",
      "monster: 220\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Historical' word frequency:\n",
      "Top 10 words with highest frequency:\n",
      "life: 191\n",
      "world: 154\n",
      "young: 145\n",
      "time: 137\n",
      "story: 132\n",
      "man: 117\n",
      "war: 116\n",
      "year: 115\n",
      "japan: 104\n",
      "family: 100\n",
      "new: 99\n",
      "girl: 91\n",
      "day: 87\n",
      "father: 85\n",
      "boy: 72\n",
      "begin: 70\n",
      "set: 68\n",
      "mother: 67\n",
      "power: 67\n",
      "make: 65\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Kids' word frequency:\n",
      "Top 10 words with highest frequency:\n",
      "world: 165\n",
      "friend: 155\n",
      "new: 117\n",
      "time: 102\n",
      "story: 101\n",
      "pokémon: 100\n",
      "child: 97\n",
      "life: 89\n",
      "series: 89\n",
      "boy: 85\n",
      "anime: 82\n",
      "named: 79\n",
      "pokemon: 78\n",
      "help: 76\n",
      "satoshi: 73\n",
      "year: 71\n",
      "adventure: 67\n",
      "character: 67\n",
      "film: 66\n",
      "meet: 66\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Mecha' word frequency:\n",
      "Top 10 words with highest frequency:\n",
      "earth: 267\n",
      "world: 213\n",
      "year: 210\n",
      "robot: 187\n",
      "new: 167\n",
      "pilot: 158\n",
      "war: 137\n",
      "life: 130\n",
      "battle: 124\n",
      "known: 121\n",
      "human: 120\n",
      "space: 108\n",
      "planet: 107\n",
      "city: 105\n",
      "mysterious: 105\n",
      "girl: 104\n",
      "fight: 102\n",
      "force: 101\n",
      "series: 100\n",
      "called: 99\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Music' word frequency:\n",
      "Top 10 words with highest frequency:\n",
      "music: 155\n",
      "idol: 137\n",
      "girl: 136\n",
      "school: 109\n",
      "new: 105\n",
      "world: 83\n",
      "band: 80\n",
      "member: 73\n",
      "life: 70\n",
      "year: 68\n",
      "story: 67\n",
      "group: 62\n",
      "day: 61\n",
      "student: 57\n",
      "high: 53\n",
      "song: 52\n",
      "video: 52\n",
      "friend: 50\n",
      "club: 49\n",
      "time: 48\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Mystery' word frequency:\n",
      "Top 10 words with highest frequency:\n",
      "world: 191\n",
      "life: 167\n",
      "school: 124\n",
      "detective: 117\n",
      "friend: 115\n",
      "mysterious: 115\n",
      "begin: 110\n",
      "girl: 107\n",
      "new: 107\n",
      "day: 106\n",
      "year: 93\n",
      "story: 91\n",
      "time: 89\n",
      "mystery: 85\n",
      "case: 79\n",
      "city: 78\n",
      "student: 77\n",
      "conan: 72\n",
      "group: 72\n",
      "young: 72\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Romance' word frequency:\n",
      "Top 10 words with highest frequency:\n",
      "school: 606\n",
      "girl: 590\n",
      "life: 512\n",
      "love: 414\n",
      "friend: 381\n",
      "new: 341\n",
      "year: 322\n",
      "day: 305\n",
      "student: 305\n",
      "world: 304\n",
      "high: 290\n",
      "time: 261\n",
      "high school: 252\n",
      "story: 199\n",
      "young: 198\n",
      "begin: 184\n",
      "boy: 183\n",
      "way: 181\n",
      "make: 177\n",
      "family: 175\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'School' word frequency:\n",
      "Top 10 words with highest frequency:\n",
      "school: 1077\n",
      "girl: 553\n",
      "student: 488\n",
      "high: 460\n",
      "high school: 394\n",
      "friend: 362\n",
      "life: 360\n",
      "club: 332\n",
      "new: 313\n",
      "day: 275\n",
      "love: 232\n",
      "year: 226\n",
      "academy: 222\n",
      "time: 196\n",
      "team: 194\n",
      "member: 189\n",
      "world: 177\n",
      "boy: 172\n",
      "class: 168\n",
      "make: 161\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Sci-Fi' word frequency:\n",
      "Top 10 words with highest frequency:\n",
      "world: 610\n",
      "earth: 502\n",
      "year: 419\n",
      "new: 410\n",
      "life: 395\n",
      "girl: 338\n",
      "human: 323\n",
      "planet: 300\n",
      "time: 290\n",
      "mysterious: 268\n",
      "space: 261\n",
      "robot: 259\n",
      "friend: 256\n",
      "known: 248\n",
      "city: 243\n",
      "alien: 241\n",
      "war: 240\n",
      "power: 237\n",
      "battle: 229\n",
      "story: 218\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Seinen' word frequency:\n",
      "Top 10 words with highest frequency:\n",
      "life: 180\n",
      "girl: 144\n",
      "school: 140\n",
      "world: 136\n",
      "new: 135\n",
      "day: 108\n",
      "friend: 105\n",
      "year: 104\n",
      "time: 90\n",
      "human: 86\n",
      "high: 85\n",
      "story: 84\n",
      "family: 82\n",
      "lupin: 79\n",
      "begin: 73\n",
      "man: 73\n",
      "student: 68\n",
      "high school: 67\n",
      "make: 64\n",
      "young: 63\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Shoujo' word frequency:\n",
      "Top 10 words with highest frequency:\n",
      "girl: 220\n",
      "school: 193\n",
      "world: 130\n",
      "new: 127\n",
      "love: 124\n",
      "friend: 113\n",
      "day: 103\n",
      "life: 101\n",
      "boy: 86\n",
      "student: 85\n",
      "time: 77\n",
      "story: 76\n",
      "human: 66\n",
      "high: 61\n",
      "begin: 59\n",
      "power: 58\n",
      "year: 58\n",
      "dream: 57\n",
      "meet: 56\n",
      "princess: 56\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Shounen' word frequency:\n",
      "Top 10 words with highest frequency:\n",
      "school: 433\n",
      "world: 413\n",
      "new: 335\n",
      "life: 327\n",
      "friend: 283\n",
      "year: 259\n",
      "team: 244\n",
      "high: 223\n",
      "time: 212\n",
      "girl: 211\n",
      "day: 210\n",
      "boy: 182\n",
      "student: 181\n",
      "power: 178\n",
      "high school: 170\n",
      "young: 169\n",
      "earth: 166\n",
      "way: 165\n",
      "story: 156\n",
      "mysterious: 155\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Slice of Life' word frequency:\n",
      "Top 10 words with highest frequency:\n",
      "school: 474\n",
      "life: 440\n",
      "girl: 380\n",
      "friend: 319\n",
      "new: 299\n",
      "day: 252\n",
      "high: 219\n",
      "time: 211\n",
      "club: 208\n",
      "year: 206\n",
      "high school: 195\n",
      "student: 195\n",
      "world: 189\n",
      "story: 183\n",
      "love: 170\n",
      "family: 158\n",
      "make: 140\n",
      "member: 128\n",
      "begin: 125\n",
      "episode: 125\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Sports' word frequency:\n",
      "Top 10 words with highest frequency:\n",
      "team: 312\n",
      "school: 266\n",
      "high: 161\n",
      "new: 119\n",
      "high school: 117\n",
      "club: 113\n",
      "player: 101\n",
      "world: 93\n",
      "baseball: 87\n",
      "tournament: 82\n",
      "sport: 79\n",
      "soccer: 78\n",
      "year: 76\n",
      "game: 74\n",
      "boy: 73\n",
      "girl: 73\n",
      "tennis: 69\n",
      "match: 68\n",
      "japan: 62\n",
      "member: 61\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Super Power' word frequency:\n",
      "Top 10 words with highest frequency:\n",
      "world: 159\n",
      "power: 131\n",
      "new: 97\n",
      "life: 85\n",
      "friend: 84\n",
      "year: 82\n",
      "city: 81\n",
      "girl: 77\n",
      "school: 67\n",
      "order: 66\n",
      "ability: 64\n",
      "time: 60\n",
      "student: 58\n",
      "mysterious: 57\n",
      "young: 56\n",
      "battle: 55\n",
      "known: 55\n",
      "hero: 54\n",
      "fight: 52\n",
      "earth: 49\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Supernatural' word frequency:\n",
      "Top 10 words with highest frequency:\n",
      "world: 333\n",
      "life: 315\n",
      "girl: 268\n",
      "school: 226\n",
      "human: 224\n",
      "friend: 217\n",
      "day: 204\n",
      "demon: 200\n",
      "year: 199\n",
      "new: 193\n",
      "power: 192\n",
      "story: 183\n",
      "time: 167\n",
      "begin: 161\n",
      "mysterious: 159\n",
      "spirit: 146\n",
      "young: 146\n",
      "student: 138\n",
      "man: 127\n",
      "high: 126\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop through each class within the OneVsRestClassifier\n",
    "for class_index, estimator in enumerate(classifier.estimators_):\n",
    "    print(f\"Class '{mlb.classes_[class_index]}' word frequency:\")\n",
    "    \n",
    "    # Get the feature names from the CountVectorizer\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "    # Sum word counts for this specific class\n",
    "    class_counts = X_train[y_train[:, class_index] == 1].sum(axis=0).A1\n",
    "\n",
    "    # Combine words with their class-specific frequencies\n",
    "    word_freq_pairs = list(zip(feature_names, class_counts))\n",
    "\n",
    "    # Sort words by frequency in descending order\n",
    "    sorted_words = sorted(word_freq_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Display the top 10 words with the highest frequencies\n",
    "    print(\"Top 10 words with highest frequency:\")\n",
    "    for word, count in sorted_words[:20]:\n",
    "        print(f\"{word}: {count}\")\n",
    "        \n",
    "    print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c06a9ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 'Action' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "battle               30.714399709121178 0.0008\n",
      "power                30.131660926729957 0.0013\n",
      "earth                28.775194704395474 0.0012\n",
      "war                  27.966394426550444 0.0008\n",
      "city                 27.477736374407822 0.0013\n",
      "human                27.37293760629922 0.0017\n",
      "fight                25.09881665533962 0.0007\n",
      "known                23.38537588058216 0.0009\n",
      "series               22.483871014160222 0.0022\n",
      "game                 21.88208379177676 0.0016\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Adventure' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "power                21.090730966950844 0.0014\n",
      "adventure            21.000099767178142 0.0007\n",
      "earth                20.805674547393153 0.0013\n",
      "journey              19.001178027265585 0.0005\n",
      "boy                  18.891187580438608 0.0017\n",
      "named                18.852220567928565 0.0014\n",
      "series               18.23467412144437 0.0021\n",
      "human                17.752683672221536 0.0018\n",
      "island               16.91080753068057 0.0008\n",
      "set                  16.282496637341758 0.0013\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Comedy' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "episode              55.43625799233053 0.0015\n",
      "series               37.86648536808389 0.0018\n",
      "anime                31.245479319750814 0.0016\n",
      "character            31.154487836175775 0.0012\n",
      "special              29.904973220257695 0.0012\n",
      "love                 27.842684526403517 0.0015\n",
      "high school          27.73932906701308 0.0013\n",
      "club                 26.272150072740427 0.0008\n",
      "family               25.839371222935497 0.0014\n",
      "boy                  23.351041829735376 0.0019\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Drama' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "love                 19.79043670510422 0.0014\n",
      "boy                  17.53776432368825 0.0017\n",
      "human                16.885403478412496 0.0018\n",
      "family               16.411310259687543 0.0014\n",
      "mother               16.073869635301435 0.0008\n",
      "father               15.597243265135228 0.0011\n",
      "earth                15.523201673479074 0.0015\n",
      "come                 14.722517864046933 0.0013\n",
      "high school          14.387662381543207 0.0014\n",
      "war                  14.053141861842114 0.0012\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Fantasy' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "power                25.05728123556651 0.0013\n",
      "demon                22.480263085776176 0.0007\n",
      "game                 22.007591550580404 0.0014\n",
      "human                21.90433600772192 0.0016\n",
      "monster              20.66575236382528 0.0006\n",
      "god                  18.085712354625503 0.0004\n",
      "named                17.82592813907254 0.0014\n",
      "dragon               17.66988547506095 0.0002\n",
      "journey              17.13619553539692 0.0006\n",
      "land                 16.894570554978067 0.0004\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Historical' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "war                  9.825744741583472 0.0011\n",
      "man                  9.659983357366864 0.0013\n",
      "japan                9.396253396090902 0.0012\n",
      "samurai              7.54666229255689 0.0002\n",
      "family               7.314297297632852 0.0014\n",
      "film                 7.292252191742378 0.0013\n",
      "father               7.088952410809808 0.0012\n",
      "mother               6.726438812061302 0.0009\n",
      "japanese             6.691652149370994 0.0009\n",
      "edo                  5.763754754114654 0.0000\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Kids' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "child                12.63701118312164 0.0010\n",
      "pokémon              11.441251619503653 0.0000\n",
      "anime                11.016164048314817 0.0016\n",
      "pokemon              10.370948724320781 0.0000\n",
      "series               10.055016979914706 0.0020\n",
      "film                 9.673402262219609 0.0012\n",
      "educational          8.943235459720572 0.0000\n",
      "pikachu              8.801927067741877 0.0000\n",
      "character            8.426196250363942 0.0015\n",
      "episode              8.184699938548583 0.0023\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Mecha' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "earth                19.722844201236786 0.0012\n",
      "robot                19.081696921680564 0.0004\n",
      "pilot                15.664788034320743 0.0003\n",
      "war                  10.86009539440681 0.0011\n",
      "planet               10.156833194320079 0.0008\n",
      "space                9.591862467425452 0.0008\n",
      "battle               9.588764109416438 0.0012\n",
      "series               9.166505195558162 0.0020\n",
      "alien                9.110890182433348 0.0006\n",
      "human                8.795483280376377 0.0017\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Music' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "music                18.821279471135625 0.0002\n",
      "idol                 16.55338860369335 0.0003\n",
      "band                 8.919897709758285 0.0002\n",
      "video                8.12813053733665 0.0008\n",
      "song                 7.440387940151905 0.0002\n",
      "group                5.758568365410604 0.0012\n",
      "member               5.653899342045498 0.0011\n",
      "anime                4.945652123131696 0.0018\n",
      "animation            4.841543609039897 0.0007\n",
      "game                 4.648180958906689 0.0016\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Mystery' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "detective            13.079063774461547 0.0001\n",
      "mystery              9.345712732867657 0.0004\n",
      "conan                8.577152111187345 0.0000\n",
      "lupin                8.262040653864867 0.0001\n",
      "case                 7.9732635753421635 0.0002\n",
      "murder               6.757687889523814 0.0002\n",
      "series               6.319151026578164 0.0021\n",
      "solve                6.035766198711188 0.0002\n",
      "city                 5.970762628528155 0.0015\n",
      "group                5.370757800325251 0.0013\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Romance' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "love                 30.00954707045123 0.0010\n",
      "high school          17.68636739417748 0.0013\n",
      "episode              15.949612799284356 0.0024\n",
      "boy                  13.54333049497712 0.0017\n",
      "relationship         13.135455957867457 0.0003\n",
      "family               12.508867002896292 0.0014\n",
      "feeling              12.488503209591736 0.0003\n",
      "come                 12.050846315042039 0.0013\n",
      "meet                 11.929124850515024 0.0012\n",
      "club                 11.230193630093472 0.0011\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'School' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "high school          28.926816609652647 0.0009\n",
      "club                 27.13062052615514 0.0006\n",
      "academy              19.738395375010434 0.0004\n",
      "love                 16.51445804157175 0.0014\n",
      "class                15.436966172538803 0.0004\n",
      "member               13.864866868656858 0.0009\n",
      "team                 13.802222911746492 0.0012\n",
      "classmate            12.767229168787779 0.0003\n",
      "episode              12.58269685916356 0.0024\n",
      "boy                  12.526826696614384 0.0017\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Sci-Fi' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "earth                37.21589149953369 0.0008\n",
      "planet               27.49345024885549 0.0003\n",
      "robot                25.79457851448061 0.0002\n",
      "space                24.60510138312865 0.0004\n",
      "alien                23.0463212434666 0.0002\n",
      "human                22.137980317603834 0.0016\n",
      "city                 18.377716397607873 0.0014\n",
      "war                  18.36857757905242 0.0010\n",
      "episode              17.985901213557174 0.0024\n",
      "pilot                17.596041457733435 0.0003\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Seinen' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "lupin                11.166308643007284 0.0000\n",
      "family               6.172031284671019 0.0015\n",
      "human                5.951222033620126 0.0018\n",
      "manga                5.934607391815021 0.0009\n",
      "man                  5.552077990986614 0.0014\n",
      "japan                5.045447692220687 0.0013\n",
      "gang                 5.038998885725583 0.0004\n",
      "team                 4.877582940036183 0.0013\n",
      "shinnosuke           4.740213029436775 0.0000\n",
      "high school          4.67588453702776 0.0015\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Shoujo' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "love                 8.599142526510688 0.0015\n",
      "boy                  6.333711726715479 0.0017\n",
      "precure              5.451904969408567 0.0000\n",
      "princess             5.377256030243259 0.0006\n",
      "cure                 5.152064337433915 0.0001\n",
      "natsume              4.720204098437214 0.0001\n",
      "dream                4.610237813745294 0.0010\n",
      "queen                4.598607254854404 0.0003\n",
      "human                4.387442274946281 0.0018\n",
      "idol                 4.22926993305386 0.0006\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Shounen' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "team                 17.089870272803385 0.0011\n",
      "episode              15.054748332787725 0.0024\n",
      "earth                13.318316606033319 0.0015\n",
      "boy                  13.141476941256904 0.0017\n",
      "power                11.956215163569825 0.0016\n",
      "high school          11.918924843327066 0.0014\n",
      "demon                11.787477858599516 0.0010\n",
      "special              11.2654475629519 0.0015\n",
      "series               10.844332966259321 0.0022\n",
      "manga                10.81854864229669 0.0009\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Slice of Life' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "club                 18.480197916955962 0.0008\n",
      "high school          14.255311302923184 0.0013\n",
      "episode              13.073384095641917 0.0024\n",
      "family               13.024859893997675 0.0014\n",
      "love                 12.902179078283648 0.0015\n",
      "anime                11.398658303337193 0.0018\n",
      "work                 10.991034182539229 0.0012\n",
      "member               9.643005272314001 0.0011\n",
      "father               9.56565084127773 0.0012\n",
      "sister               9.516168570064623 0.0010\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Sports' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "team                 21.550640696768745 0.0008\n",
      "baseball             11.692685956522073 0.0001\n",
      "player               10.491666658295065 0.0002\n",
      "soccer               10.41391269683532 0.0000\n",
      "sport                9.085687138690263 0.0001\n",
      "club                 8.934595132816401 0.0010\n",
      "high school          8.093908184726644 0.0014\n",
      "tournament           7.897764287767568 0.0003\n",
      "tennis               7.116805468380358 0.0000\n",
      "match                7.039131923080138 0.0002\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Super Power' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "power                9.580667276036925 0.0015\n",
      "city                 5.618799864013637 0.0015\n",
      "ability              4.95203932633248 0.0007\n",
      "goku                 4.796773180483782 0.0001\n",
      "special              4.781309449652682 0.0015\n",
      "hero                 4.472211733110623 0.0007\n",
      "order                4.411138317934143 0.0012\n",
      "fight                4.318956601920979 0.0011\n",
      "naruto               4.246699650827649 0.0001\n",
      "episode              4.224369037382759 0.0024\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Supernatural' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "demon                17.8474818165486 0.0007\n",
      "human                15.462449657919187 0.0017\n",
      "power                13.59381603091293 0.0015\n",
      "spirit               13.446509498952402 0.0006\n",
      "supernatural         11.401938587623718 0.0001\n",
      "god                  11.146760763263138 0.0006\n",
      "ghost                10.55113540532596 0.0003\n",
      "vampire              10.277625966246138 0.0001\n",
      "youkai               10.2056953154963 0.0000\n",
      "man                  9.246362562740511 0.0014\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop through each class within the OneVsRestClassifier\n",
    "for class_index, estimator in enumerate(classifier.estimators_):\n",
    "    print(f\"Class '{mlb.classes_[class_index]}' word frequency and probability:\")\n",
    "\n",
    "    # Get the feature names from the CountVectorizer\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "    # Sum word counts for this specific class (already calculated previously)\n",
    "    class_counts = X_train[y_train[:, class_index] == 1].sum(axis=0).A1\n",
    "\n",
    "    # Extract the log probabilities from the Naive Bayes model\n",
    "    log_prob = estimator.feature_log_prob_\n",
    "\n",
    "    # Convert log probabilities to normal probabilities\n",
    "    prob = np.exp(log_prob)\n",
    "\n",
    "    # Combine words with their counts and probabilities\n",
    "    word_stats = list(zip(feature_names, class_counts, prob[0]))\n",
    "\n",
    "    # Sort words by frequency in descending order\n",
    "    sorted_words = sorted(word_stats, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Display the top 10 words with the highest frequencies and their probabilities\n",
    "    print(\"Top 10 words with highest frequency and probability:\")\n",
    "    print(f\"{'Word':<20} {'Frequency':<10} {'Probability':<15}\")\n",
    "    print(\"=\" * 50)\n",
    "    for word, count, probability in sorted_words[:10]:\n",
    "        print(f\"{word:<20} {count:<10} {probability:.4f}\")\n",
    "        \n",
    "    print(\"\\n\" + \"=\" * 50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f5b729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Text: pilot battle planet robot fight in space\n",
      "predicted probabilities\n",
      "Action=0.9782900665570801\n",
      "Adventure=0.7902130161703154\n",
      "Comedy=0.045823235119317275\n",
      "Drama=0.11854035354265431\n",
      "Fantasy=0.008760036390328992\n",
      "Historical=0.00033741773093282144\n",
      "Kids=0.016330815543897998\n",
      "Mecha=0.9996635088045812\n",
      "Music=0.0004826158807966897\n",
      "Mystery=6.392538670231276e-05\n",
      "Romance=0.005021570394863842\n",
      "School=0.0001289826277087438\n",
      "Sci-Fi=0.9999339752660713\n",
      "Seinen=0.006037486045298855\n",
      "Shoujo=9.257094658479882e-07\n",
      "Shounen=0.17990872489299573\n",
      "Slice of Life=3.388315669380318e-05\n",
      "Sports=0.0008339333859334194\n",
      "Super Power=0.007333325875266134\n",
      "Supernatural=5.230719980664343e-05\n",
      "\n",
      "Step 2: Mapping Features\n",
      "Words present in the sample:\n",
      "- battle (Index: 764)\n",
      "- fight (Index: 3041)\n",
      "- pilot (Index: 6445)\n",
      "- planet (Index: 6481)\n",
      "- robot (Index: 7307)\n",
      "- space (Index: 8165)\n",
      "\n",
      "Step 3: Extracting Model Parameters\n",
      "\n",
      "Class: Action\n",
      "Log Prior: -0.3751, Prior Probability: 0.6872\n",
      "\n",
      "Calculating log probability:\n",
      "Word: battle               Log P(word|Action): -6.7403\n",
      "Word: fight                Log P(word|Action): -6.8322\n",
      "Word: pilot                Log P(word|Action): -7.7162\n",
      "Word: planet               Log P(word|Action): -7.0292\n",
      "Word: robot                Log P(word|Action): -7.0348\n",
      "Word: space                Log P(word|Action): -6.9437\n",
      "\n",
      "Log Sum for Action: -42.6715\n",
      "Final Probability for Action: 0.0000\n",
      "\n",
      "Class: Adventure\n",
      "Log Prior: -0.2459, Prior Probability: 0.7820\n",
      "\n",
      "Calculating log probability:\n",
      "Word: battle               Log P(word|Adventure): -6.3356\n",
      "Word: fight                Log P(word|Adventure): -6.4366\n",
      "Word: pilot                Log P(word|Adventure): -7.2159\n",
      "Word: planet               Log P(word|Adventure): -6.9541\n",
      "Word: robot                Log P(word|Adventure): -6.9673\n",
      "Word: space                Log P(word|Adventure): -7.0216\n",
      "\n",
      "Log Sum for Adventure: -41.1770\n",
      "Final Probability for Adventure: 0.0000\n",
      "\n",
      "Class: Comedy\n",
      "Log Prior: -0.5262, Prior Probability: 0.5909\n",
      "\n",
      "Calculating log probability:\n",
      "Word: battle               Log P(word|Comedy): -6.0174\n",
      "Word: fight                Log P(word|Comedy): -6.2993\n",
      "Word: pilot                Log P(word|Comedy): -6.9312\n",
      "Word: planet               Log P(word|Comedy): -6.5440\n",
      "Word: robot                Log P(word|Comedy): -6.8195\n",
      "Word: space                Log P(word|Comedy): -6.6599\n",
      "\n",
      "Log Sum for Comedy: -39.7974\n",
      "Final Probability for Comedy: 0.0000\n",
      "\n",
      "Class: Drama\n",
      "Log Prior: -0.2318, Prior Probability: 0.7931\n",
      "\n",
      "Calculating log probability:\n",
      "Word: battle               Log P(word|Drama): -6.1212\n",
      "Word: fight                Log P(word|Drama): -6.2989\n",
      "Word: pilot                Log P(word|Drama): -7.3096\n",
      "Word: planet               Log P(word|Drama): -6.6952\n",
      "Word: robot                Log P(word|Drama): -6.8335\n",
      "Word: space                Log P(word|Drama): -6.7766\n",
      "\n",
      "Log Sum for Drama: -40.2669\n",
      "Final Probability for Drama: 0.0000\n",
      "\n",
      "Class: Fantasy\n",
      "Log Prior: -0.2702, Prior Probability: 0.7632\n",
      "\n",
      "Calculating log probability:\n",
      "Word: battle               Log P(word|Fantasy): -6.2748\n",
      "Word: fight                Log P(word|Fantasy): -6.3970\n",
      "Word: pilot                Log P(word|Fantasy): -6.9928\n",
      "Word: planet               Log P(word|Fantasy): -6.5906\n",
      "Word: robot                Log P(word|Fantasy): -6.7478\n",
      "Word: space                Log P(word|Fantasy): -6.5813\n",
      "\n",
      "Log Sum for Fantasy: -39.8546\n",
      "Final Probability for Fantasy: 0.0000\n",
      "\n",
      "Class: Historical\n",
      "Log Prior: -0.0772, Prior Probability: 0.9257\n",
      "\n",
      "Calculating log probability:\n",
      "Word: battle               Log P(word|Historical): -6.2079\n",
      "Word: fight                Log P(word|Historical): -6.3529\n",
      "Word: pilot                Log P(word|Historical): -7.1543\n",
      "Word: planet               Log P(word|Historical): -6.6340\n",
      "Word: robot                Log P(word|Historical): -6.8460\n",
      "Word: space                Log P(word|Historical): -6.7101\n",
      "\n",
      "Log Sum for Historical: -39.9824\n",
      "Final Probability for Historical: 0.0000\n",
      "\n",
      "Class: Kids\n",
      "Log Prior: -0.0871, Prior Probability: 0.9166\n",
      "\n",
      "Calculating log probability:\n",
      "Word: battle               Log P(word|Kids): -6.2046\n",
      "Word: fight                Log P(word|Kids): -6.3465\n",
      "Word: pilot                Log P(word|Kids): -7.1538\n",
      "Word: planet               Log P(word|Kids): -6.6829\n",
      "Word: robot                Log P(word|Kids): -6.9438\n",
      "Word: space                Log P(word|Kids): -6.7793\n",
      "\n",
      "Log Sum for Kids: -40.1981\n",
      "Final Probability for Kids: 0.0000\n",
      "\n",
      "Class: Mecha\n",
      "Log Prior: -0.0793, Prior Probability: 0.9237\n",
      "\n",
      "Calculating log probability:\n",
      "Word: battle               Log P(word|Mecha): -6.3283\n",
      "Word: fight                Log P(word|Mecha): -6.4860\n",
      "Word: pilot                Log P(word|Mecha): -8.2387\n",
      "Word: planet               Log P(word|Mecha): -6.9285\n",
      "Word: robot                Log P(word|Mecha): -7.7102\n",
      "Word: space                Log P(word|Mecha): -7.0370\n",
      "\n",
      "Log Sum for Mecha: -42.8081\n",
      "Final Probability for Mecha: 0.0000\n",
      "\n",
      "Class: Music\n",
      "Log Prior: -0.0528, Prior Probability: 0.9486\n",
      "\n",
      "Calculating log probability:\n",
      "Word: battle               Log P(word|Music): -6.1815\n",
      "Word: fight                Log P(word|Music): -6.3397\n",
      "Word: pilot                Log P(word|Music): -7.1936\n",
      "Word: planet               Log P(word|Music): -6.6715\n",
      "Word: robot                Log P(word|Music): -6.8649\n",
      "Word: space                Log P(word|Music): -6.7708\n",
      "\n",
      "Log Sum for Music: -40.0748\n",
      "Final Probability for Music: 0.0000\n",
      "\n",
      "Class: Mystery\n",
      "Log Prior: -0.0689, Prior Probability: 0.9334\n",
      "\n",
      "Calculating log probability:\n",
      "Word: battle               Log P(word|Mystery): -6.1608\n",
      "Word: fight                Log P(word|Mystery): -6.3314\n",
      "Word: pilot                Log P(word|Mystery): -7.1305\n",
      "Word: planet               Log P(word|Mystery): -6.6346\n",
      "Word: robot                Log P(word|Mystery): -6.8537\n",
      "Word: space                Log P(word|Mystery): -6.7194\n",
      "\n",
      "Log Sum for Mystery: -39.8993\n",
      "Final Probability for Mystery: 0.0000\n",
      "\n",
      "Class: Romance\n",
      "Log Prior: -0.1837, Prior Probability: 0.8322\n",
      "\n",
      "Calculating log probability:\n",
      "Word: battle               Log P(word|Romance): -6.0910\n",
      "Word: fight                Log P(word|Romance): -6.2806\n",
      "Word: pilot                Log P(word|Romance): -7.1840\n",
      "Word: planet               Log P(word|Romance): -6.5867\n",
      "Word: robot                Log P(word|Romance): -6.7927\n",
      "Word: space                Log P(word|Romance): -6.6672\n",
      "\n",
      "Log Sum for Romance: -39.7861\n",
      "Final Probability for Romance: 0.0000\n",
      "\n",
      "Class: School\n",
      "Log Prior: -0.1461, Prior Probability: 0.8640\n",
      "\n",
      "Calculating log probability:\n",
      "Word: battle               Log P(word|School): -6.1233\n",
      "Word: fight                Log P(word|School): -6.3421\n",
      "Word: pilot                Log P(word|School): -7.0655\n",
      "Word: planet               Log P(word|School): -6.5460\n",
      "Word: robot                Log P(word|School): -6.7958\n",
      "Word: space                Log P(word|School): -6.6397\n",
      "\n",
      "Log Sum for School: -39.6584\n",
      "Final Probability for School: 0.0000\n",
      "\n",
      "Class: Sci-Fi\n",
      "Log Prior: -0.2223, Prior Probability: 0.8007\n",
      "\n",
      "Calculating log probability:\n",
      "Word: battle               Log P(word|Sci-Fi): -6.3942\n",
      "Word: fight                Log P(word|Sci-Fi): -6.5358\n",
      "Word: pilot                Log P(word|Sci-Fi): -8.3460\n",
      "Word: planet               Log P(word|Sci-Fi): -7.9184\n",
      "Word: robot                Log P(word|Sci-Fi): -8.3633\n",
      "Word: space                Log P(word|Sci-Fi): -7.8020\n",
      "\n",
      "Log Sum for Sci-Fi: -45.5819\n",
      "Final Probability for Sci-Fi: 0.0000\n",
      "\n",
      "Class: Seinen\n",
      "Log Prior: -0.0739, Prior Probability: 0.9288\n",
      "\n",
      "Calculating log probability:\n",
      "Word: battle               Log P(word|Seinen): -6.2086\n",
      "Word: fight                Log P(word|Seinen): -6.3861\n",
      "Word: pilot                Log P(word|Seinen): -7.1937\n",
      "Word: planet               Log P(word|Seinen): -6.6303\n",
      "Word: robot                Log P(word|Seinen): -6.8712\n",
      "Word: space                Log P(word|Seinen): -6.7465\n",
      "\n",
      "Log Sum for Seinen: -40.1102\n",
      "Final Probability for Seinen: 0.0000\n",
      "\n",
      "Class: Shoujo\n",
      "Log Prior: -0.0581, Prior Probability: 0.9435\n",
      "\n",
      "Calculating log probability:\n",
      "Word: battle               Log P(word|Shoujo): -6.1638\n",
      "Word: fight                Log P(word|Shoujo): -6.3548\n",
      "Word: pilot                Log P(word|Shoujo): -7.1438\n",
      "Word: planet               Log P(word|Shoujo): -6.6735\n",
      "Word: robot                Log P(word|Shoujo): -6.8393\n",
      "Word: space                Log P(word|Shoujo): -6.7229\n",
      "\n",
      "Log Sum for Shoujo: -39.9563\n",
      "Final Probability for Shoujo: 0.0000\n",
      "\n",
      "Class: Shounen\n",
      "Log Prior: -0.1747, Prior Probability: 0.8397\n",
      "\n",
      "Calculating log probability:\n",
      "Word: battle               Log P(word|Shounen): -6.2389\n",
      "Word: fight                Log P(word|Shounen): -6.4148\n",
      "Word: pilot                Log P(word|Shounen): -7.1440\n",
      "Word: planet               Log P(word|Shounen): -6.7806\n",
      "Word: robot                Log P(word|Shounen): -6.9005\n",
      "Word: space                Log P(word|Shounen): -6.7338\n",
      "\n",
      "Log Sum for Shounen: -40.3872\n",
      "Final Probability for Shounen: 0.0000\n",
      "\n",
      "Class: Slice of Life\n",
      "Log Prior: -0.1520, Prior Probability: 0.8590\n",
      "\n",
      "Calculating log probability:\n",
      "Word: battle               Log P(word|Slice of Life): -6.0948\n",
      "Word: fight                Log P(word|Slice of Life): -6.2754\n",
      "Word: pilot                Log P(word|Slice of Life): -7.0759\n",
      "Word: planet               Log P(word|Slice of Life): -6.5749\n",
      "Word: robot                Log P(word|Slice of Life): -6.8126\n",
      "Word: space                Log P(word|Slice of Life): -6.6576\n",
      "\n",
      "Log Sum for Slice of Life: -39.6432\n",
      "Final Probability for Slice of Life: 0.0000\n",
      "\n",
      "Class: Sports\n",
      "Log Prior: -0.0520, Prior Probability: 0.9493\n",
      "\n",
      "Calculating log probability:\n",
      "Word: battle               Log P(word|Sports): -6.2074\n",
      "Word: fight                Log P(word|Sports): -6.3725\n",
      "Word: pilot                Log P(word|Sports): -7.1670\n",
      "Word: planet               Log P(word|Sports): -6.6767\n",
      "Word: robot                Log P(word|Sports): -6.8611\n",
      "Word: space                Log P(word|Sports): -6.7260\n",
      "\n",
      "Log Sum for Sports: -40.0628\n",
      "Final Probability for Sports: 0.0000\n",
      "\n",
      "Class: Super Power\n",
      "Log Prior: -0.0513, Prior Probability: 0.9500\n",
      "\n",
      "Calculating log probability:\n",
      "Word: battle               Log P(word|Super Power): -6.2331\n",
      "Word: fight                Log P(word|Super Power): -6.4089\n",
      "Word: pilot                Log P(word|Super Power): -7.1630\n",
      "Word: planet               Log P(word|Super Power): -6.6986\n",
      "Word: robot                Log P(word|Super Power): -6.8582\n",
      "Word: space                Log P(word|Super Power): -6.7664\n",
      "\n",
      "Log Sum for Super Power: -40.1794\n",
      "Final Probability for Super Power: 0.0000\n",
      "\n",
      "Class: Supernatural\n",
      "Log Prior: -0.1366, Prior Probability: 0.8723\n",
      "\n",
      "Calculating log probability:\n",
      "Word: battle               Log P(word|Supernatural): -6.2072\n",
      "Word: fight                Log P(word|Supernatural): -6.3913\n",
      "Word: pilot                Log P(word|Supernatural): -7.0667\n",
      "Word: planet               Log P(word|Supernatural): -6.5551\n",
      "Word: robot                Log P(word|Supernatural): -6.7639\n",
      "Word: space                Log P(word|Supernatural): -6.6455\n",
      "\n",
      "Log Sum for Supernatural: -39.7663\n",
      "Final Probability for Supernatural: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Input Text Preprocessing\n",
    "sample_text = \"pilot battle planet robot fight in space\"\n",
    "print(f\"Sample Text: {sample_text}\")\n",
    "\n",
    "# Vectorize the input text using the same vectorizer used for training\n",
    "X_sample = vectorizer.transform([sample_text])\n",
    "pred=classifier.predict_proba(X_sample)\n",
    "print(\"predicted probabilities\")\n",
    "for i in range(0,len(pred[0].tolist())):\n",
    "    print(f\"{all_genres[i]}={pred[0][i]}\")\n",
    "# Step 2: Mapping Features\n",
    "print(\"\\nStep 2: Mapping Features\")\n",
    "present_word_indices = X_sample.nonzero()[1]  # Get indices of non-zero features\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(f\"Words present in the sample:\")\n",
    "for index in present_word_indices:\n",
    "    print(f\"- {feature_names[index]} (Index: {index})\")\n",
    "\n",
    "# Step 3: Extracting Model Parameters\n",
    "print(\"\\nStep 3: Extracting Model Parameters\")\n",
    "for class_index, estimator in enumerate(classifier.estimators_):\n",
    "    class_name = mlb.classes_[class_index]\n",
    "    print(f\"\\nClass: {class_name}\")\n",
    "\n",
    "    # Get the prior probability for the class\n",
    "    prior_log = estimator.class_log_prior_[0]\n",
    "    prior = np.exp(prior_log)\n",
    "    print(f\"Log Prior: {prior_log:.4f}, Prior Probability: {prior:.4f}\")\n",
    "\n",
    "    # Get the log probabilities for words in the class\n",
    "    log_prob = estimator.feature_log_prob_[0]\n",
    "\n",
    "    # Step 4: Calculating Log Probabilities\n",
    "    log_prob_class = prior_log  # Start with the log prior\n",
    "\n",
    "    print(\"\\nCalculating log probability:\")\n",
    "    for index in present_word_indices:\n",
    "        word = feature_names[index]\n",
    "        word_log_prob = log_prob[index]\n",
    "        log_prob_class += word_log_prob\n",
    "        print(f\"Word: {word:<20} Log P(word|{class_name}): {word_log_prob:.4f}\")\n",
    "\n",
    "    # Step 5: Exponentiation to Get Final Probability\n",
    "    final_prob = np.exp(log_prob_class)\n",
    "    print(f\"\\nLog Sum for {class_name}: {log_prob_class:.4f}\")\n",
    "    print(f\"Final Probability for {class_name}: {final_prob:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd74e023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word            Class1     Class2     Log Odds Ratio      \n",
      "============================================================\n",
      "love            -6.2083    -6.9367    0.7284\n",
      "action          -8.0055    -7.6971    -0.3084\n",
      "friend          -5.9538    -6.1105    0.1567\n",
      "school          -5.6020    -5.9294    0.3274\n",
      "battle          -7.1918    -6.5452    -0.6466\n",
      "fight           -7.2422    -6.7200    -0.5222\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# List of specific words to check\n",
    "specific_words = [\"love\", \"action\", \"friend\", \"school\", \"battle\", \"fight\"]  # Modify this list as needed\n",
    "\n",
    "# Classes to compare (you can customize this)\n",
    "class1 = \"Action\"\n",
    "class2 = \"Romance\"\n",
    "\n",
    "# Find the indices of the classes\n",
    "try:\n",
    "    class1_index = list(mlb.classes_).index(class1)\n",
    "    class2_index = list(mlb.classes_).index(class2)\n",
    "except ValueError:\n",
    "    print(f\"One or both classes '{class1}' and '{class2}' not found.\")\n",
    "    exit()\n",
    "\n",
    "# Print the header\n",
    "print(f\"{'Word':<15} {'Class1':<10} {'Class2':<10} {'Log Odds Ratio':<20}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Loop through each specific word\n",
    "for word in specific_words:\n",
    "    # Find the index of the word in the vocabulary\n",
    "    try:\n",
    "        word_index = vectorizer.vocabulary_[word]\n",
    "    except KeyError:\n",
    "        print(f\"{word:<15} Not in vocab\")\n",
    "        continue\n",
    "\n",
    "    # Get the estimators for both classes\n",
    "    estimator1 = classifier.estimators_[class1_index]\n",
    "    estimator2 = classifier.estimators_[class2_index]\n",
    "\n",
    "    # Get log probabilities for the word in both classes\n",
    "    log_prob1 = estimator1.feature_log_prob_[0, word_index]\n",
    "    log_prob2 = estimator2.feature_log_prob_[0, word_index]\n",
    "\n",
    "    # Calculate log odds ratio\n",
    "    log_odds_ratio = log_prob1 - log_prob2\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"{word:<15} {log_prob1:.4f}    {log_prob2:.4f}    {log_odds_ratio:.4f}\")\n",
    "\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa4e6feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: 'love'\n",
      "Class                Probability    \n",
      "==================================================\n",
      "Word 'love' not found in vocabulary.\n",
      "==================================================\n",
      "\n",
      "Word: 'action'\n",
      "Class                Probability    \n",
      "==================================================\n",
      "Action               0.0001\n",
      "Adventure            0.0001\n",
      "Comedy               0.0001\n",
      "Drama                0.0001\n",
      "Fantasy              0.0001\n",
      "Historical           0.0001\n",
      "Kids                 0.0001\n",
      "Mecha                0.0001\n",
      "Music                0.0001\n",
      "Mystery              0.0001\n",
      "Romance              0.0001\n",
      "School               0.0001\n",
      "Sci-Fi               0.0001\n",
      "Seinen               0.0001\n",
      "Shoujo               0.0001\n",
      "Shounen              0.0001\n",
      "Slice of Life        0.0001\n",
      "Sports               0.0001\n",
      "Super Power          0.0001\n",
      "Supernatural         0.0001\n",
      "==================================================\n",
      "\n",
      "Word: 'friend'\n",
      "Class                Probability    \n",
      "==================================================\n",
      "Word 'friend' not found in vocabulary.\n",
      "==================================================\n",
      "\n",
      "Word: 'school'\n",
      "Class                Probability    \n",
      "==================================================\n",
      "Word 'school' not found in vocabulary.\n",
      "==================================================\n",
      "\n",
      "Word: 'battle'\n",
      "Class                Probability    \n",
      "==================================================\n",
      "Word 'battle' not found in vocabulary.\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of specific words to check\n",
    "specific_words = [\"love\", \"action\", \"friend\", \"school\", \"battle\"]  # Modify this list as needed\n",
    "\n",
    "# Loop through each class within the OneVsRestClassifier\n",
    "for word in specific_words:\n",
    "    print(f\"Word: '{word}'\")\n",
    "    print(f\"{'Class':<20} {'Probability':<15}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Find the index of the word in the vocabulary\n",
    "    try:\n",
    "        word_index = vectorizer.vocabulary_[word]\n",
    "    except KeyError:\n",
    "        print(f\"Word '{word}' not found in vocabulary.\")\n",
    "        print(\"=\" * 50 + \"\\n\")\n",
    "        continue\n",
    "\n",
    "    # Loop through each class and print the word probability\n",
    "    for class_index, estimator in enumerate(classifier.estimators_):\n",
    "        # Get the class name\n",
    "        class_name = mlb.classes_[class_index]\n",
    "\n",
    "        # Extract the log probabilities from the Naive Bayes model\n",
    "        log_prob = estimator.feature_log_prob_\n",
    "\n",
    "        # Convert log probabilities to normal probabilities\n",
    "        prob = np.exp(log_prob)\n",
    "\n",
    "        # Get the probability of the word given the class\n",
    "        word_prob = prob[0, word_index]\n",
    "        word_log_prob=log_prob[0, word_index]\n",
    "\n",
    "        # Print the class name and word probability\n",
    "        print(f\"{class_name:<20} {word_prob:.4f}\")\n",
    "\n",
    "    print(\"=\" * 50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "84fdb028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Top Word 1 (Prob)",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Top Word 2 (Prob)",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Top Word 3 (Prob)",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Top Word 4 (Prob)",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Top Word 5 (Prob)",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "9c3281c8-6e71-4b5b-a805-d9e4d303b366",
       "rows": [
        [
         "Action",
         "episode (0.0028)",
         "series (0.0022)",
         "anime (0.0021)",
         "love (0.0021)",
         "boy (0.0020)"
        ],
        [
         "Adventure",
         "episode (0.0025)",
         "anime (0.0021)",
         "series (0.0021)",
         "love (0.0019)",
         "high school (0.0018)"
        ],
        [
         "Comedy",
         "human (0.0021)",
         "boy (0.0019)",
         "power (0.0018)",
         "city (0.0018)",
         "earth (0.0018)"
        ],
        [
         "Drama",
         "episode (0.0026)",
         "series (0.0022)",
         "anime (0.0021)",
         "character (0.0018)",
         "game (0.0018)"
        ],
        [
         "Fantasy",
         "episode (0.0027)",
         "series (0.0022)",
         "anime (0.0020)",
         "boy (0.0019)",
         "high school (0.0018)"
        ],
        [
         "Historical",
         "episode (0.0024)",
         "series (0.0021)",
         "human (0.0019)",
         "anime (0.0018)",
         "boy (0.0018)"
        ],
        [
         "Kids",
         "episode (0.0023)",
         "series (0.0020)",
         "human (0.0018)",
         "boy (0.0017)",
         "love (0.0017)"
        ],
        [
         "Mecha",
         "episode (0.0024)",
         "series (0.0020)",
         "anime (0.0019)",
         "boy (0.0019)",
         "human (0.0017)"
        ],
        [
         "Music",
         "episode (0.0024)",
         "series (0.0021)",
         "human (0.0019)",
         "boy (0.0018)",
         "anime (0.0018)"
        ],
        [
         "Mystery",
         "episode (0.0025)",
         "series (0.0021)",
         "anime (0.0019)",
         "human (0.0019)",
         "boy (0.0018)"
        ],
        [
         "Romance",
         "episode (0.0024)",
         "series (0.0022)",
         "anime (0.0021)",
         "human (0.0019)",
         "boy (0.0017)"
        ],
        [
         "School",
         "episode (0.0024)",
         "series (0.0022)",
         "human (0.0020)",
         "anime (0.0019)",
         "earth (0.0018)"
        ],
        [
         "Sci-Fi",
         "episode (0.0024)",
         "series (0.0021)",
         "anime (0.0020)",
         "boy (0.0019)",
         "love (0.0018)"
        ],
        [
         "Seinen",
         "episode (0.0025)",
         "series (0.0021)",
         "boy (0.0019)",
         "anime (0.0019)",
         "human (0.0018)"
        ],
        [
         "Shoujo",
         "episode (0.0024)",
         "series (0.0021)",
         "anime (0.0019)",
         "human (0.0018)",
         "boy (0.0017)"
        ],
        [
         "Shounen",
         "episode (0.0024)",
         "series (0.0022)",
         "anime (0.0020)",
         "human (0.0019)",
         "love (0.0018)"
        ],
        [
         "Slice of Life",
         "episode (0.0024)",
         "series (0.0022)",
         "human (0.0019)",
         "boy (0.0018)",
         "power (0.0018)"
        ],
        [
         "Sports",
         "episode (0.0024)",
         "series (0.0021)",
         "human (0.0019)",
         "anime (0.0018)",
         "boy (0.0018)"
        ],
        [
         "Super Power",
         "episode (0.0024)",
         "series (0.0021)",
         "human (0.0019)",
         "anime (0.0019)",
         "boy (0.0018)"
        ],
        [
         "Supernatural",
         "episode (0.0025)",
         "series (0.0021)",
         "anime (0.0020)",
         "boy (0.0018)",
         "game (0.0017)"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top Word 1 (Prob)</th>\n",
       "      <th>Top Word 2 (Prob)</th>\n",
       "      <th>Top Word 3 (Prob)</th>\n",
       "      <th>Top Word 4 (Prob)</th>\n",
       "      <th>Top Word 5 (Prob)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Action</th>\n",
       "      <td>episode (0.0028)</td>\n",
       "      <td>series (0.0022)</td>\n",
       "      <td>anime (0.0021)</td>\n",
       "      <td>love (0.0021)</td>\n",
       "      <td>boy (0.0020)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adventure</th>\n",
       "      <td>episode (0.0025)</td>\n",
       "      <td>anime (0.0021)</td>\n",
       "      <td>series (0.0021)</td>\n",
       "      <td>love (0.0019)</td>\n",
       "      <td>high school (0.0018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comedy</th>\n",
       "      <td>human (0.0021)</td>\n",
       "      <td>boy (0.0019)</td>\n",
       "      <td>power (0.0018)</td>\n",
       "      <td>city (0.0018)</td>\n",
       "      <td>earth (0.0018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drama</th>\n",
       "      <td>episode (0.0026)</td>\n",
       "      <td>series (0.0022)</td>\n",
       "      <td>anime (0.0021)</td>\n",
       "      <td>character (0.0018)</td>\n",
       "      <td>game (0.0018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fantasy</th>\n",
       "      <td>episode (0.0027)</td>\n",
       "      <td>series (0.0022)</td>\n",
       "      <td>anime (0.0020)</td>\n",
       "      <td>boy (0.0019)</td>\n",
       "      <td>high school (0.0018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Historical</th>\n",
       "      <td>episode (0.0024)</td>\n",
       "      <td>series (0.0021)</td>\n",
       "      <td>human (0.0019)</td>\n",
       "      <td>anime (0.0018)</td>\n",
       "      <td>boy (0.0018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kids</th>\n",
       "      <td>episode (0.0023)</td>\n",
       "      <td>series (0.0020)</td>\n",
       "      <td>human (0.0018)</td>\n",
       "      <td>boy (0.0017)</td>\n",
       "      <td>love (0.0017)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mecha</th>\n",
       "      <td>episode (0.0024)</td>\n",
       "      <td>series (0.0020)</td>\n",
       "      <td>anime (0.0019)</td>\n",
       "      <td>boy (0.0019)</td>\n",
       "      <td>human (0.0017)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Music</th>\n",
       "      <td>episode (0.0024)</td>\n",
       "      <td>series (0.0021)</td>\n",
       "      <td>human (0.0019)</td>\n",
       "      <td>boy (0.0018)</td>\n",
       "      <td>anime (0.0018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mystery</th>\n",
       "      <td>episode (0.0025)</td>\n",
       "      <td>series (0.0021)</td>\n",
       "      <td>anime (0.0019)</td>\n",
       "      <td>human (0.0019)</td>\n",
       "      <td>boy (0.0018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Romance</th>\n",
       "      <td>episode (0.0024)</td>\n",
       "      <td>series (0.0022)</td>\n",
       "      <td>anime (0.0021)</td>\n",
       "      <td>human (0.0019)</td>\n",
       "      <td>boy (0.0017)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>School</th>\n",
       "      <td>episode (0.0024)</td>\n",
       "      <td>series (0.0022)</td>\n",
       "      <td>human (0.0020)</td>\n",
       "      <td>anime (0.0019)</td>\n",
       "      <td>earth (0.0018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sci-Fi</th>\n",
       "      <td>episode (0.0024)</td>\n",
       "      <td>series (0.0021)</td>\n",
       "      <td>anime (0.0020)</td>\n",
       "      <td>boy (0.0019)</td>\n",
       "      <td>love (0.0018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seinen</th>\n",
       "      <td>episode (0.0025)</td>\n",
       "      <td>series (0.0021)</td>\n",
       "      <td>boy (0.0019)</td>\n",
       "      <td>anime (0.0019)</td>\n",
       "      <td>human (0.0018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shoujo</th>\n",
       "      <td>episode (0.0024)</td>\n",
       "      <td>series (0.0021)</td>\n",
       "      <td>anime (0.0019)</td>\n",
       "      <td>human (0.0018)</td>\n",
       "      <td>boy (0.0017)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shounen</th>\n",
       "      <td>episode (0.0024)</td>\n",
       "      <td>series (0.0022)</td>\n",
       "      <td>anime (0.0020)</td>\n",
       "      <td>human (0.0019)</td>\n",
       "      <td>love (0.0018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slice of Life</th>\n",
       "      <td>episode (0.0024)</td>\n",
       "      <td>series (0.0022)</td>\n",
       "      <td>human (0.0019)</td>\n",
       "      <td>boy (0.0018)</td>\n",
       "      <td>power (0.0018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sports</th>\n",
       "      <td>episode (0.0024)</td>\n",
       "      <td>series (0.0021)</td>\n",
       "      <td>human (0.0019)</td>\n",
       "      <td>anime (0.0018)</td>\n",
       "      <td>boy (0.0018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Super Power</th>\n",
       "      <td>episode (0.0024)</td>\n",
       "      <td>series (0.0021)</td>\n",
       "      <td>human (0.0019)</td>\n",
       "      <td>anime (0.0019)</td>\n",
       "      <td>boy (0.0018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Supernatural</th>\n",
       "      <td>episode (0.0025)</td>\n",
       "      <td>series (0.0021)</td>\n",
       "      <td>anime (0.0020)</td>\n",
       "      <td>boy (0.0018)</td>\n",
       "      <td>game (0.0017)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Top Word 1 (Prob) Top Word 2 (Prob) Top Word 3 (Prob)  \\\n",
       "Action         episode (0.0028)   series (0.0022)    anime (0.0021)   \n",
       "Adventure      episode (0.0025)    anime (0.0021)   series (0.0021)   \n",
       "Comedy           human (0.0021)      boy (0.0019)    power (0.0018)   \n",
       "Drama          episode (0.0026)   series (0.0022)    anime (0.0021)   \n",
       "Fantasy        episode (0.0027)   series (0.0022)    anime (0.0020)   \n",
       "Historical     episode (0.0024)   series (0.0021)    human (0.0019)   \n",
       "Kids           episode (0.0023)   series (0.0020)    human (0.0018)   \n",
       "Mecha          episode (0.0024)   series (0.0020)    anime (0.0019)   \n",
       "Music          episode (0.0024)   series (0.0021)    human (0.0019)   \n",
       "Mystery        episode (0.0025)   series (0.0021)    anime (0.0019)   \n",
       "Romance        episode (0.0024)   series (0.0022)    anime (0.0021)   \n",
       "School         episode (0.0024)   series (0.0022)    human (0.0020)   \n",
       "Sci-Fi         episode (0.0024)   series (0.0021)    anime (0.0020)   \n",
       "Seinen         episode (0.0025)   series (0.0021)      boy (0.0019)   \n",
       "Shoujo         episode (0.0024)   series (0.0021)    anime (0.0019)   \n",
       "Shounen        episode (0.0024)   series (0.0022)    anime (0.0020)   \n",
       "Slice of Life  episode (0.0024)   series (0.0022)    human (0.0019)   \n",
       "Sports         episode (0.0024)   series (0.0021)    human (0.0019)   \n",
       "Super Power    episode (0.0024)   series (0.0021)    human (0.0019)   \n",
       "Supernatural   episode (0.0025)   series (0.0021)    anime (0.0020)   \n",
       "\n",
       "                Top Word 4 (Prob)     Top Word 5 (Prob)  \n",
       "Action              love (0.0021)          boy (0.0020)  \n",
       "Adventure           love (0.0019)  high school (0.0018)  \n",
       "Comedy              city (0.0018)        earth (0.0018)  \n",
       "Drama          character (0.0018)         game (0.0018)  \n",
       "Fantasy              boy (0.0019)  high school (0.0018)  \n",
       "Historical         anime (0.0018)          boy (0.0018)  \n",
       "Kids                 boy (0.0017)         love (0.0017)  \n",
       "Mecha                boy (0.0019)        human (0.0017)  \n",
       "Music                boy (0.0018)        anime (0.0018)  \n",
       "Mystery            human (0.0019)          boy (0.0018)  \n",
       "Romance            human (0.0019)          boy (0.0017)  \n",
       "School             anime (0.0019)        earth (0.0018)  \n",
       "Sci-Fi               boy (0.0019)         love (0.0018)  \n",
       "Seinen             anime (0.0019)        human (0.0018)  \n",
       "Shoujo             human (0.0018)          boy (0.0017)  \n",
       "Shounen            human (0.0019)         love (0.0018)  \n",
       "Slice of Life        boy (0.0018)        power (0.0018)  \n",
       "Sports             anime (0.0018)          boy (0.0018)  \n",
       "Super Power        anime (0.0019)          boy (0.0018)  \n",
       "Supernatural         boy (0.0018)         game (0.0017)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create an empty dictionary to store genres as keys and top words with probabilities as lists\n",
    "genre_words = {}\n",
    "\n",
    "# Loop through each class within the OneVsRestClassifier\n",
    "for class_index, estimator in enumerate(classifier.estimators_):\n",
    "    # Get the genre name\n",
    "    genre_name = mlb.classes_[class_index]\n",
    "    \n",
    "    # Get the feature names from the CountVectorizer\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    \n",
    "    # Extract the log probabilities from the Naive Bayes model\n",
    "    log_prob = estimator.feature_log_prob_\n",
    "    \n",
    "    # Convert log probabilities to normal probabilities\n",
    "    prob = np.exp(log_prob)\n",
    "    \n",
    "    # Combine words with their probabilities\n",
    "    word_stats = list(zip(feature_names, prob[0]))\n",
    "    \n",
    "    # Sort words by probability in descending order\n",
    "    sorted_words = sorted(word_stats, key=lambda x: x[1], reverse=True)[:5]\n",
    "    \n",
    "    # Create a list to store the top 5 words and their probabilities as strings\n",
    "    top_words_with_probs = [f\"{word} ({probability:.4f})\" for word, probability in sorted_words]\n",
    "    \n",
    "    # Store the top words with probabilities in the dictionary with genre as the key\n",
    "    genre_words[genre_name] = top_words_with_probs\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "df_top_words = pd.DataFrame.from_dict(genre_words, orient='index', columns=[f'Top Word {i+1} (Prob)' for i in range(5)])\n",
    "\n",
    "# Display the DataFrame\n",
    "display(df_top_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0abbaf34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Genre",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Top Word 1",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Top Word 2",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Top Word 3",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Top Word 4",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Top Word 5",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "a3b5148d-63af-4975-a0ed-62a688812d40",
       "rows": [
        [
         "0",
         "Action",
         "girl",
         "school",
         "life",
         "story",
         "episode"
        ],
        [
         "1",
         "Adventure",
         "school",
         "girl",
         "life",
         "story",
         "new"
        ],
        [
         "2",
         "Comedy",
         "world",
         "life",
         "girl",
         "story",
         "school"
        ],
        [
         "3",
         "Drama",
         "world",
         "girl",
         "school",
         "new",
         "life"
        ],
        [
         "4",
         "Fantasy",
         "school",
         "girl",
         "life",
         "new",
         "story"
        ],
        [
         "5",
         "Historical",
         "girl",
         "school",
         "world",
         "life",
         "new"
        ],
        [
         "6",
         "Kids",
         "girl",
         "school",
         "world",
         "life",
         "new"
        ],
        [
         "7",
         "Mecha",
         "girl",
         "school",
         "world",
         "life",
         "story"
        ],
        [
         "8",
         "Music",
         "world",
         "girl",
         "school",
         "life",
         "new"
        ],
        [
         "9",
         "Mystery",
         "girl",
         "world",
         "school",
         "life",
         "new"
        ],
        [
         "10",
         "Romance",
         "world",
         "life",
         "girl",
         "new",
         "story"
        ],
        [
         "11",
         "School",
         "world",
         "life",
         "girl",
         "story",
         "new"
        ],
        [
         "12",
         "Sci-Fi",
         "school",
         "girl",
         "life",
         "world",
         "story"
        ],
        [
         "13",
         "Seinen",
         "world",
         "girl",
         "school",
         "life",
         "new"
        ],
        [
         "14",
         "Shoujo",
         "world",
         "life",
         "girl",
         "school",
         "new"
        ],
        [
         "15",
         "Shounen",
         "girl",
         "world",
         "life",
         "school",
         "story"
        ],
        [
         "16",
         "Slice of Life",
         "world",
         "girl",
         "school",
         "life",
         "new"
        ],
        [
         "17",
         "Sports",
         "world",
         "girl",
         "life",
         "school",
         "new"
        ],
        [
         "18",
         "Super Power",
         "girl",
         "world",
         "school",
         "life",
         "new"
        ],
        [
         "19",
         "Supernatural",
         "girl",
         "world",
         "school",
         "life",
         "new"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>Top Word 1</th>\n",
       "      <th>Top Word 2</th>\n",
       "      <th>Top Word 3</th>\n",
       "      <th>Top Word 4</th>\n",
       "      <th>Top Word 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Action</td>\n",
       "      <td>girl</td>\n",
       "      <td>school</td>\n",
       "      <td>life</td>\n",
       "      <td>story</td>\n",
       "      <td>episode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adventure</td>\n",
       "      <td>school</td>\n",
       "      <td>girl</td>\n",
       "      <td>life</td>\n",
       "      <td>story</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Comedy</td>\n",
       "      <td>world</td>\n",
       "      <td>life</td>\n",
       "      <td>girl</td>\n",
       "      <td>story</td>\n",
       "      <td>school</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Drama</td>\n",
       "      <td>world</td>\n",
       "      <td>girl</td>\n",
       "      <td>school</td>\n",
       "      <td>new</td>\n",
       "      <td>life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fantasy</td>\n",
       "      <td>school</td>\n",
       "      <td>girl</td>\n",
       "      <td>life</td>\n",
       "      <td>new</td>\n",
       "      <td>story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Historical</td>\n",
       "      <td>girl</td>\n",
       "      <td>school</td>\n",
       "      <td>world</td>\n",
       "      <td>life</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kids</td>\n",
       "      <td>girl</td>\n",
       "      <td>school</td>\n",
       "      <td>world</td>\n",
       "      <td>life</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mecha</td>\n",
       "      <td>girl</td>\n",
       "      <td>school</td>\n",
       "      <td>world</td>\n",
       "      <td>life</td>\n",
       "      <td>story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Music</td>\n",
       "      <td>world</td>\n",
       "      <td>girl</td>\n",
       "      <td>school</td>\n",
       "      <td>life</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mystery</td>\n",
       "      <td>girl</td>\n",
       "      <td>world</td>\n",
       "      <td>school</td>\n",
       "      <td>life</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Romance</td>\n",
       "      <td>world</td>\n",
       "      <td>life</td>\n",
       "      <td>girl</td>\n",
       "      <td>new</td>\n",
       "      <td>story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>School</td>\n",
       "      <td>world</td>\n",
       "      <td>life</td>\n",
       "      <td>girl</td>\n",
       "      <td>story</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sci-Fi</td>\n",
       "      <td>school</td>\n",
       "      <td>girl</td>\n",
       "      <td>life</td>\n",
       "      <td>world</td>\n",
       "      <td>story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Seinen</td>\n",
       "      <td>world</td>\n",
       "      <td>girl</td>\n",
       "      <td>school</td>\n",
       "      <td>life</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Shoujo</td>\n",
       "      <td>world</td>\n",
       "      <td>life</td>\n",
       "      <td>girl</td>\n",
       "      <td>school</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Shounen</td>\n",
       "      <td>girl</td>\n",
       "      <td>world</td>\n",
       "      <td>life</td>\n",
       "      <td>school</td>\n",
       "      <td>story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Slice of Life</td>\n",
       "      <td>world</td>\n",
       "      <td>girl</td>\n",
       "      <td>school</td>\n",
       "      <td>life</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sports</td>\n",
       "      <td>world</td>\n",
       "      <td>girl</td>\n",
       "      <td>life</td>\n",
       "      <td>school</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Super Power</td>\n",
       "      <td>girl</td>\n",
       "      <td>world</td>\n",
       "      <td>school</td>\n",
       "      <td>life</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Supernatural</td>\n",
       "      <td>girl</td>\n",
       "      <td>world</td>\n",
       "      <td>school</td>\n",
       "      <td>life</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Genre Top Word 1 Top Word 2 Top Word 3 Top Word 4 Top Word 5\n",
       "0          Action       girl     school       life      story    episode\n",
       "1       Adventure     school       girl       life      story        new\n",
       "2          Comedy      world       life       girl      story     school\n",
       "3           Drama      world       girl     school        new       life\n",
       "4         Fantasy     school       girl       life        new      story\n",
       "5      Historical       girl     school      world       life        new\n",
       "6            Kids       girl     school      world       life        new\n",
       "7           Mecha       girl     school      world       life      story\n",
       "8           Music      world       girl     school       life        new\n",
       "9         Mystery       girl      world     school       life        new\n",
       "10        Romance      world       life       girl        new      story\n",
       "11         School      world       life       girl      story        new\n",
       "12         Sci-Fi     school       girl       life      world      story\n",
       "13         Seinen      world       girl     school       life        new\n",
       "14         Shoujo      world       life       girl     school        new\n",
       "15        Shounen       girl      world       life     school      story\n",
       "16  Slice of Life      world       girl     school       life        new\n",
       "17         Sports      world       girl       life     school        new\n",
       "18    Super Power       girl      world     school       life        new\n",
       "19   Supernatural       girl      world     school       life        new"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create an empty dictionary to store genre and top words\n",
    "genre_words = {\"Genre\": [], \"Top Word 1\": [], \"Top Word 2\": [], \"Top Word 3\": [], \"Top Word 4\": [], \"Top Word 5\": []}\n",
    "\n",
    "# Loop through each class within the OneVsRestClassifier\n",
    "for class_index, estimator in enumerate(classifier.estimators_):\n",
    "    # Get the genre name\n",
    "    genre_name = mlb.classes_[class_index]\n",
    "    \n",
    "    # Get the feature names from the CountVectorizer\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    \n",
    "    # Extract the log probabilities from the Naive Bayes model\n",
    "    log_prob = estimator.feature_log_prob_\n",
    "    \n",
    "    # Convert log probabilities to normal probabilities\n",
    "    prob = np.exp(log_prob)\n",
    "    \n",
    "    # Combine words with their probabilities\n",
    "    word_stats = list(zip(feature_names, prob[0]))\n",
    "    \n",
    "    # Sort words by probability in descending order\n",
    "    sorted_words = sorted(word_stats, key=lambda x: x[1], reverse=True)[:5]\n",
    "    \n",
    "    # Extract the top 5 words for this genre\n",
    "    top_words = [word for word, _ in sorted_words]\n",
    "    \n",
    "    # Store in the dictionary\n",
    "    genre_words[\"Genre\"].append(genre_name)\n",
    "    for i in range(5):\n",
    "        genre_words[f\"Top Word {i+1}\"].append(top_words[i] if i < len(top_words) else '')\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_top_words = pd.DataFrame(genre_words)\n",
    "\n",
    "# Display the DataFrame\n",
    "display(df_top_words)\n",
    "df_top_words.to_csv(\"words TFDIFMNB.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0613d922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 'Action' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "girl                 23.20604349156397 0.0038\n",
      "school               22.22172762061093 0.0037\n",
      "life                 30.518717822260026 0.0032\n",
      "story                22.43560423819046 0.0030\n",
      "episode              18.16317049678781 0.0027\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Adventure' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "school               7.021763915518274 0.0037\n",
      "girl                 15.527458285555731 0.0035\n",
      "life                 21.23209520185186 0.0031\n",
      "story                18.086930303661905 0.0027\n",
      "new                  23.361935277302965 0.0027\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Comedy' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "world                42.905534166486014 0.0034\n",
      "life                 45.998563003830526 0.0029\n",
      "girl                 53.947874928371725 0.0029\n",
      "story                35.15764762184822 0.0028\n",
      "school               59.130963278238966 0.0025\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Drama' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "world                23.5242385692736 0.0033\n",
      "girl                 25.902034167339153 0.0032\n",
      "school               25.687717732315786 0.0031\n",
      "new                  21.934538961310654 0.0027\n",
      "life                 32.22665494074874 0.0027\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Fantasy' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "school               12.86811230878866 0.0036\n",
      "girl                 26.37613317474003 0.0032\n",
      "life                 26.55455082503645 0.0030\n",
      "new                  25.105421106613555 0.0027\n",
      "story                22.83461754916318 0.0026\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Historical' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "girl                 5.523143570183931 0.0033\n",
      "school               2.807532271384309 0.0032\n",
      "world                7.797003562318278 0.0032\n",
      "life                 11.06540375826668 0.0029\n",
      "new                  5.635473178519332 0.0028\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Kids' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "girl                 4.421064157753024 0.0033\n",
      "school               4.0154347531145245 0.0032\n",
      "world                10.147893435197764 0.0031\n",
      "life                 6.397519497806812 0.0030\n",
      "new                  7.343324786456084 0.0027\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Mecha' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "girl                 5.823098240725516 0.0033\n",
      "school               3.6335273144314617 0.0032\n",
      "world                11.6984552981583 0.0031\n",
      "life                 6.779331665114491 0.0030\n",
      "story                5.142049899965493 0.0027\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Music' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "world                4.895751315261281 0.0032\n",
      "girl                 8.533651643609558 0.0031\n",
      "school               5.6625269273251355 0.0031\n",
      "life                 3.7439236513973198 0.0030\n",
      "new                  6.756209837566913 0.0027\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Mystery' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "girl                 5.6874756549802825 0.0032\n",
      "world                9.962822533024232 0.0032\n",
      "school               6.677549561450513 0.0031\n",
      "life                 8.512823698636282 0.0030\n",
      "new                  6.0672493912529655 0.0028\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Romance' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "world                15.240734940888936 0.0034\n",
      "life                 25.71984772111777 0.0028\n",
      "girl                 33.1569433876168 0.0028\n",
      "new                  18.601019592942027 0.0027\n",
      "story                15.14657895443255 0.0027\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'School' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "world                9.309758825093853 0.0034\n",
      "life                 18.434143886522115 0.0029\n",
      "girl                 30.698589674769668 0.0027\n",
      "story                10.435496419162714 0.0027\n",
      "new                  16.830662814389854 0.0027\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Sci-Fi' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "school               12.197003506418095 0.0035\n",
      "girl                 19.31409244477278 0.0033\n",
      "life                 20.54185100949724 0.0031\n",
      "world                32.81415236262013 0.0029\n",
      "story                16.453317859973854 0.0028\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Seinen' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "world                7.069659815137467 0.0032\n",
      "girl                 8.257097565504042 0.0032\n",
      "school               8.051501728669379 0.0031\n",
      "life                 9.331604930740175 0.0029\n",
      "new                  7.744222830686743 0.0027\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Shoujo' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "world                6.472785752746081 0.0032\n",
      "life                 5.656157129086832 0.0030\n",
      "girl                 12.735913347979514 0.0030\n",
      "school               11.013519227898412 0.0029\n",
      "new                  7.6497865353086025 0.0027\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Shounen' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "girl                 11.69947705170721 0.0034\n",
      "world                21.24542341789271 0.0032\n",
      "life                 16.704384857861477 0.0030\n",
      "school               22.871916811997988 0.0030\n",
      "story                10.935721444162509 0.0028\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Slice of Life' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "world                10.089755234174692 0.0034\n",
      "girl                 22.737573740707123 0.0030\n",
      "school               26.78126714503868 0.0027\n",
      "life                 26.248052140372373 0.0027\n",
      "new                  17.413025961228236 0.0026\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Sports' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "world                4.834217522098386 0.0032\n",
      "girl                 4.042978716136892 0.0032\n",
      "life                 2.720854926866822 0.0031\n",
      "school               13.109410708685747 0.0029\n",
      "new                  6.608278256826973 0.0027\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Super Power' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "girl                 4.067766698987591 0.0032\n",
      "world                8.503588572885294 0.0031\n",
      "school               3.7633046146640035 0.0031\n",
      "life                 4.196021856353287 0.0030\n",
      "new                  5.708770857764506 0.0027\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 'Supernatural' word frequency and probability:\n",
      "Top 10 words with highest frequency and probability:\n",
      "Word                 Frequency  Probability    \n",
      "==================================================\n",
      "girl                 14.692173480278361 0.0032\n",
      "world                16.68708783016543 0.0032\n",
      "school               11.953568185125132 0.0032\n",
      "life                 15.707067654000003 0.0030\n",
      "new                  10.920898992442035 0.0028\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop through each class within the OneVsRestClassifier\n",
    "for class_index, estimator in enumerate(classifier.estimators_):\n",
    "    print(f\"Class '{mlb.classes_[class_index]}' word frequency and probability:\")\n",
    "\n",
    "    # Get the feature names from the CountVectorizer\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "    # Sum word counts for this specific class (already calculated previously)\n",
    "    class_counts = X_train[y_train[:, class_index] == 1].sum(axis=0).A1\n",
    "\n",
    "    # Extract the log probabilities from the Naive Bayes model\n",
    "    log_prob = estimator.feature_log_prob_\n",
    "\n",
    "    # Convert log probabilities to normal probabilities\n",
    "    prob = np.exp(log_prob)\n",
    "\n",
    "    # Combine words with their counts and probabilities\n",
    "    word_stats = list(zip(feature_names, class_counts, prob[0]))\n",
    "\n",
    "    \n",
    "    sorted_words = sorted(word_stats, key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    # Display the top 10 words with the highest frequencies and their probabilities\n",
    "    print(\"Top 10 words with highest frequency and probability:\")\n",
    "    print(f\"{'Word':<20} {'Frequency':<10} {'Probability':<15}\")\n",
    "    print(\"=\" * 50)\n",
    "    for word, count, probability in sorted_words[0:5]:\n",
    "        print(f\"{word:<20} {count:<10} {probability:.4f}\")\n",
    "        \n",
    "    print(\"\\n\" + \"=\" * 50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83fb6df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Top Word 1",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Top Word 2",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Top Word 3",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Top Word 4",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Top Word 5",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "36da6f1e-51bd-4018-b3b4-e76ede2a1b13",
       "rows": [
        [
         "Action",
         "gokuu (-2.2827) ",
         "gunpla (-2.0762) ",
         "kirito (-2.0265) ",
         "kamui (-2.0214) ",
         "educational (1.9891) "
        ],
        [
         "Adventure",
         "pokémon (-2.3152) ",
         "sinbad (-2.3018) ",
         "gohan (-2.2846) ",
         "eureka (-2.2389) ",
         "goemon (-2.2051) "
        ],
        [
         "Comedy",
         "comedic (-2.1100) ",
         "doraemon (-2.1016) ",
         "tenchi (-2.1006) ",
         "hilarious (-2.0666) ",
         "arale (-2.0144) "
        ],
        [
         "Drama",
         "karasuno (-2.2872) ",
         "taisei (-2.0778) ",
         "sensou (-2.0447) ",
         "hiroki (-2.0149) ",
         "arslan (-2.0026) "
        ],
        [
         "Fantasy",
         "pokémon (-2.5996) ",
         "precure (-2.5336) ",
         "pokemon (-2.2959) ",
         "kirito (-2.2385) ",
         "rimuru (-2.2250) "
        ],
        [
         "Historical",
         "hijikata (-2.5632) ",
         "genji (-2.5353) ",
         "melos (-2.4556) ",
         "lucius (-2.4449) ",
         "holo (-2.4378) "
        ],
        [
         "Kids",
         "pokémon (-3.2473) ",
         "pokemon (-2.9245) ",
         "backkom (-2.8969) ",
         "shobu (-2.8557) ",
         "pikachu (-2.8521) "
        ],
        [
         "Mecha",
         "zeon (-3.0724) ",
         "mobile suit (-2.9506) ",
         "gundam (-2.9076) ",
         "gunpla (-2.8360) ",
         "universal century (-2.5962) "
        ],
        [
         "Music",
         "shower tv (-2.8074) ",
         "space shower (-2.8074) ",
         "space shower tv (-2.8074) ",
         "pripara (-2.7673) ",
         "id directed (-2.7288) "
        ],
        [
         "Mystery",
         "mikiya (-2.8941) ",
         "edogawa (-2.8809) ",
         "conan edogawa (-2.7702) ",
         "kindaichi (-2.7386) ",
         "detective boy (-2.6883) "
        ],
        [
         "Romance",
         "tomoya (-2.6007) ",
         "lum (-2.3359) ",
         "issei (-2.3291) ",
         "negi (-2.2678) ",
         "belldandy (-2.1859) "
        ],
        [
         "School",
         "rito (-2.5446) ",
         "karasuno (-2.5160) ",
         "issei (-2.4363) ",
         "ooarai (-2.4076) ",
         "hachiman (-2.2113) "
        ],
        [
         "Sci-Fi",
         "arale (-2.4362) ",
         "reinhard (-2.4344) ",
         "rito (-2.3404) ",
         "space pirate (-2.2744) ",
         "lum (-2.2390) "
        ],
        [
         "Seinen",
         "nohara (-2.9776) ",
         "nohara family (-2.8560) ",
         "zenigata (-2.7485) ",
         "jigen (-2.7262) ",
         "belldandy (-2.5985) "
        ],
        [
         "Shoujo",
         "precure (-3.2218) ",
         "pretty cure (-2.9029) ",
         "pripara (-2.6997) ",
         "precure girl (-2.6335) ",
         "kahoko (-2.5413) "
        ],
        [
         "Shounen",
         "arale (-2.5631) ",
         "rito (-2.4673) ",
         "karasuno (-2.4387) ",
         "kinnikuman (-2.3876) ",
         "conan edogawa (-2.3792) "
        ],
        [
         "Slice of Life",
         "peeping life (-2.4881) ",
         "retsuko (-2.4410) ",
         "haré (-2.2498) ",
         "asahigaoka (-2.2365) ",
         "hoshitani (-2.2062) "
        ],
        [
         "Sports",
         "boxer (-2.9943) ",
         "karasuno (-2.9628) ",
         "kinnikuman (-2.9117) ",
         "tennis team (-2.8769) ",
         "seirin (-2.8708) "
        ],
        [
         "Super Power",
         "locke (-2.8601) ",
         "izuku (-2.7203) ",
         "academy city (-2.7187) ",
         "midoriya (-2.6885) ",
         "deku (-2.6545) "
        ],
        [
         "Supernatural",
         "yato (-2.4346) ",
         "belldandy (-2.3266) ",
         "onmyouji (-2.2988) ",
         "araragi (-2.2876) ",
         "kitarou (-2.2845) "
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top Word 1</th>\n",
       "      <th>Top Word 2</th>\n",
       "      <th>Top Word 3</th>\n",
       "      <th>Top Word 4</th>\n",
       "      <th>Top Word 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Action</th>\n",
       "      <td>gokuu (-2.2827)</td>\n",
       "      <td>gunpla (-2.0762)</td>\n",
       "      <td>kirito (-2.0265)</td>\n",
       "      <td>kamui (-2.0214)</td>\n",
       "      <td>educational (1.9891)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adventure</th>\n",
       "      <td>pokémon (-2.3152)</td>\n",
       "      <td>sinbad (-2.3018)</td>\n",
       "      <td>gohan (-2.2846)</td>\n",
       "      <td>eureka (-2.2389)</td>\n",
       "      <td>goemon (-2.2051)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comedy</th>\n",
       "      <td>comedic (-2.1100)</td>\n",
       "      <td>doraemon (-2.1016)</td>\n",
       "      <td>tenchi (-2.1006)</td>\n",
       "      <td>hilarious (-2.0666)</td>\n",
       "      <td>arale (-2.0144)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drama</th>\n",
       "      <td>karasuno (-2.2872)</td>\n",
       "      <td>taisei (-2.0778)</td>\n",
       "      <td>sensou (-2.0447)</td>\n",
       "      <td>hiroki (-2.0149)</td>\n",
       "      <td>arslan (-2.0026)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fantasy</th>\n",
       "      <td>pokémon (-2.5996)</td>\n",
       "      <td>precure (-2.5336)</td>\n",
       "      <td>pokemon (-2.2959)</td>\n",
       "      <td>kirito (-2.2385)</td>\n",
       "      <td>rimuru (-2.2250)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Historical</th>\n",
       "      <td>hijikata (-2.5632)</td>\n",
       "      <td>genji (-2.5353)</td>\n",
       "      <td>melos (-2.4556)</td>\n",
       "      <td>lucius (-2.4449)</td>\n",
       "      <td>holo (-2.4378)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kids</th>\n",
       "      <td>pokémon (-3.2473)</td>\n",
       "      <td>pokemon (-2.9245)</td>\n",
       "      <td>backkom (-2.8969)</td>\n",
       "      <td>shobu (-2.8557)</td>\n",
       "      <td>pikachu (-2.8521)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mecha</th>\n",
       "      <td>zeon (-3.0724)</td>\n",
       "      <td>mobile suit (-2.9506)</td>\n",
       "      <td>gundam (-2.9076)</td>\n",
       "      <td>gunpla (-2.8360)</td>\n",
       "      <td>universal century (-2.5962)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Music</th>\n",
       "      <td>shower tv (-2.8074)</td>\n",
       "      <td>space shower (-2.8074)</td>\n",
       "      <td>space shower tv (-2.8074)</td>\n",
       "      <td>pripara (-2.7673)</td>\n",
       "      <td>id directed (-2.7288)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mystery</th>\n",
       "      <td>mikiya (-2.8941)</td>\n",
       "      <td>edogawa (-2.8809)</td>\n",
       "      <td>conan edogawa (-2.7702)</td>\n",
       "      <td>kindaichi (-2.7386)</td>\n",
       "      <td>detective boy (-2.6883)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Romance</th>\n",
       "      <td>tomoya (-2.6007)</td>\n",
       "      <td>lum (-2.3359)</td>\n",
       "      <td>issei (-2.3291)</td>\n",
       "      <td>negi (-2.2678)</td>\n",
       "      <td>belldandy (-2.1859)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>School</th>\n",
       "      <td>rito (-2.5446)</td>\n",
       "      <td>karasuno (-2.5160)</td>\n",
       "      <td>issei (-2.4363)</td>\n",
       "      <td>ooarai (-2.4076)</td>\n",
       "      <td>hachiman (-2.2113)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sci-Fi</th>\n",
       "      <td>arale (-2.4362)</td>\n",
       "      <td>reinhard (-2.4344)</td>\n",
       "      <td>rito (-2.3404)</td>\n",
       "      <td>space pirate (-2.2744)</td>\n",
       "      <td>lum (-2.2390)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seinen</th>\n",
       "      <td>nohara (-2.9776)</td>\n",
       "      <td>nohara family (-2.8560)</td>\n",
       "      <td>zenigata (-2.7485)</td>\n",
       "      <td>jigen (-2.7262)</td>\n",
       "      <td>belldandy (-2.5985)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shoujo</th>\n",
       "      <td>precure (-3.2218)</td>\n",
       "      <td>pretty cure (-2.9029)</td>\n",
       "      <td>pripara (-2.6997)</td>\n",
       "      <td>precure girl (-2.6335)</td>\n",
       "      <td>kahoko (-2.5413)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shounen</th>\n",
       "      <td>arale (-2.5631)</td>\n",
       "      <td>rito (-2.4673)</td>\n",
       "      <td>karasuno (-2.4387)</td>\n",
       "      <td>kinnikuman (-2.3876)</td>\n",
       "      <td>conan edogawa (-2.3792)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slice of Life</th>\n",
       "      <td>peeping life (-2.4881)</td>\n",
       "      <td>retsuko (-2.4410)</td>\n",
       "      <td>haré (-2.2498)</td>\n",
       "      <td>asahigaoka (-2.2365)</td>\n",
       "      <td>hoshitani (-2.2062)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sports</th>\n",
       "      <td>boxer (-2.9943)</td>\n",
       "      <td>karasuno (-2.9628)</td>\n",
       "      <td>kinnikuman (-2.9117)</td>\n",
       "      <td>tennis team (-2.8769)</td>\n",
       "      <td>seirin (-2.8708)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Super Power</th>\n",
       "      <td>locke (-2.8601)</td>\n",
       "      <td>izuku (-2.7203)</td>\n",
       "      <td>academy city (-2.7187)</td>\n",
       "      <td>midoriya (-2.6885)</td>\n",
       "      <td>deku (-2.6545)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Supernatural</th>\n",
       "      <td>yato (-2.4346)</td>\n",
       "      <td>belldandy (-2.3266)</td>\n",
       "      <td>onmyouji (-2.2988)</td>\n",
       "      <td>araragi (-2.2876)</td>\n",
       "      <td>kitarou (-2.2845)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Top Word 1                Top Word 2  \\\n",
       "Action                gokuu (-2.2827)          gunpla (-2.0762)    \n",
       "Adventure           pokémon (-2.3152)          sinbad (-2.3018)    \n",
       "Comedy              comedic (-2.1100)        doraemon (-2.1016)    \n",
       "Drama              karasuno (-2.2872)          taisei (-2.0778)    \n",
       "Fantasy             pokémon (-2.5996)         precure (-2.5336)    \n",
       "Historical         hijikata (-2.5632)           genji (-2.5353)    \n",
       "Kids                pokémon (-3.2473)         pokemon (-2.9245)    \n",
       "Mecha                  zeon (-3.0724)     mobile suit (-2.9506)    \n",
       "Music             shower tv (-2.8074)    space shower (-2.8074)    \n",
       "Mystery              mikiya (-2.8941)         edogawa (-2.8809)    \n",
       "Romance              tomoya (-2.6007)             lum (-2.3359)    \n",
       "School                 rito (-2.5446)        karasuno (-2.5160)    \n",
       "Sci-Fi                arale (-2.4362)        reinhard (-2.4344)    \n",
       "Seinen               nohara (-2.9776)   nohara family (-2.8560)    \n",
       "Shoujo              precure (-3.2218)     pretty cure (-2.9029)    \n",
       "Shounen               arale (-2.5631)            rito (-2.4673)    \n",
       "Slice of Life  peeping life (-2.4881)         retsuko (-2.4410)    \n",
       "Sports                boxer (-2.9943)        karasuno (-2.9628)    \n",
       "Super Power           locke (-2.8601)           izuku (-2.7203)    \n",
       "Supernatural           yato (-2.4346)       belldandy (-2.3266)    \n",
       "\n",
       "                               Top Word 3               Top Word 4  \\\n",
       "Action                  kirito (-2.0265)          kamui (-2.0214)    \n",
       "Adventure                gohan (-2.2846)         eureka (-2.2389)    \n",
       "Comedy                  tenchi (-2.1006)      hilarious (-2.0666)    \n",
       "Drama                   sensou (-2.0447)         hiroki (-2.0149)    \n",
       "Fantasy                pokemon (-2.2959)         kirito (-2.2385)    \n",
       "Historical               melos (-2.4556)         lucius (-2.4449)    \n",
       "Kids                   backkom (-2.8969)          shobu (-2.8557)    \n",
       "Mecha                   gundam (-2.9076)         gunpla (-2.8360)    \n",
       "Music          space shower tv (-2.8074)        pripara (-2.7673)    \n",
       "Mystery          conan edogawa (-2.7702)      kindaichi (-2.7386)    \n",
       "Romance                  issei (-2.3291)           negi (-2.2678)    \n",
       "School                   issei (-2.4363)         ooarai (-2.4076)    \n",
       "Sci-Fi                    rito (-2.3404)   space pirate (-2.2744)    \n",
       "Seinen                zenigata (-2.7485)          jigen (-2.7262)    \n",
       "Shoujo                 pripara (-2.6997)   precure girl (-2.6335)    \n",
       "Shounen               karasuno (-2.4387)     kinnikuman (-2.3876)    \n",
       "Slice of Life             haré (-2.2498)     asahigaoka (-2.2365)    \n",
       "Sports              kinnikuman (-2.9117)    tennis team (-2.8769)    \n",
       "Super Power       academy city (-2.7187)       midoriya (-2.6885)    \n",
       "Supernatural          onmyouji (-2.2988)        araragi (-2.2876)    \n",
       "\n",
       "                                 Top Word 5  \n",
       "Action                educational (1.9891)   \n",
       "Adventure                 goemon (-2.2051)   \n",
       "Comedy                     arale (-2.0144)   \n",
       "Drama                     arslan (-2.0026)   \n",
       "Fantasy                   rimuru (-2.2250)   \n",
       "Historical                  holo (-2.4378)   \n",
       "Kids                     pikachu (-2.8521)   \n",
       "Mecha          universal century (-2.5962)   \n",
       "Music                id directed (-2.7288)   \n",
       "Mystery            detective boy (-2.6883)   \n",
       "Romance                belldandy (-2.1859)   \n",
       "School                  hachiman (-2.2113)   \n",
       "Sci-Fi                       lum (-2.2390)   \n",
       "Seinen                 belldandy (-2.5985)   \n",
       "Shoujo                    kahoko (-2.5413)   \n",
       "Shounen            conan edogawa (-2.3792)   \n",
       "Slice of Life          hoshitani (-2.2062)   \n",
       "Sports                    seirin (-2.8708)   \n",
       "Super Power                 deku (-2.6545)   \n",
       "Supernatural             kitarou (-2.2845)   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the DataFrame with column names\n",
    "influential_words_df = pd.DataFrame(columns=[f\"Top Word {i+1}\" for i in range(5)])\n",
    "\n",
    "for class_index, estimator in enumerate(classifier.estimators_):\n",
    "    genre_name = mlb.classes_[class_index]\n",
    "    \n",
    "    # Get feature names and log probabilities\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    log_prob = estimator.feature_log_prob_\n",
    "\n",
    "    # Calculate log odds (difference between current class and the average of others)\n",
    "    log_odds = log_prob[0] - np.mean(log_prob, axis=0)\n",
    "\n",
    "    # Combine words with their log-odds\n",
    "    word_stats = list(zip(feature_names, log_odds))\n",
    "\n",
    "    # Sort words by absolute log-odds in descending order\n",
    "    sorted_words = sorted(word_stats, key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "    # Select the top 5 most influential words\n",
    "    top_5_words = [f\"{word} ({log_odds:.4f}) \" for word, log_odds in sorted_words[:5]]#({log_odds:.4f})\n",
    "\n",
    "    # Add the top words to the DataFrame as a new row\n",
    "    influential_words_df.loc[genre_name] = pd.Series(top_5_words, index=influential_words_df.columns)\n",
    "\n",
    "# Display the DataFrame\n",
    "display(influential_words_df)\n",
    "\n",
    "#influential_words_df.to_csv('MNB words.csv',  index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1177e979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 Thresh\n",
      "\n",
      "📊 Evaluation Metrics:\n",
      "                 Metric     Value\n",
      "0              F1 Score  0.394592\n",
      "1             Precision  0.833870\n",
      "2                Recall  0.290355\n",
      "3  Exact Match Accuracy  0.105381\n",
      "4          Hamming Loss  0.112164\n",
      "5         Jaccard Score  0.260417\n",
      "6              Hit Rate  0.633408\n",
      "7               ROC AUC  0.847346\n",
      "\n",
      "📊 Evaluation Metrics:\n",
      "                 Metric     Value\n",
      "0              F1 Score  0.383092\n",
      "1             Precision  0.805268\n",
      "2                Recall  0.278333\n",
      "3  Exact Match Accuracy  0.093154\n",
      "4          Hamming Loss  0.112795\n",
      "5         Jaccard Score  0.249858\n",
      "6              Hit Rate  0.598204\n",
      "7               ROC AUC  0.848243\n",
      "F1 Thresh\n",
      "Label 0: Best threshold = 0.37, F1 = 0.6957\n",
      "Label 1: Best threshold = 0.28, F1 = 0.6050\n",
      "Label 2: Best threshold = 0.37, F1 = 0.6675\n",
      "Label 3: Best threshold = 0.28, F1 = 0.5101\n",
      "Label 4: Best threshold = 0.37, F1 = 0.6056\n",
      "Label 5: Best threshold = 0.12, F1 = 0.6154\n",
      "Label 6: Best threshold = 0.14, F1 = 0.5578\n",
      "Label 7: Best threshold = 0.11, F1 = 0.6057\n",
      "Label 8: Best threshold = 0.13, F1 = 0.4706\n",
      "Label 9: Best threshold = 0.14, F1 = 0.5253\n",
      "Label 10: Best threshold = 0.23, F1 = 0.6062\n",
      "Label 11: Best threshold = 0.41, F1 = 0.6296\n",
      "Label 12: Best threshold = 0.29, F1 = 0.6721\n",
      "Label 13: Best threshold = 0.17, F1 = 0.2727\n",
      "Label 14: Best threshold = 0.16, F1 = 0.3864\n",
      "Label 15: Best threshold = 0.22, F1 = 0.4651\n",
      "Label 16: Best threshold = 0.27, F1 = 0.5349\n",
      "Label 17: Best threshold = 0.17, F1 = 0.8049\n",
      "Label 18: Best threshold = 0.12, F1 = 0.2857\n",
      "Label 19: Best threshold = 0.23, F1 = 0.5962\n",
      "\n",
      "📊 Evaluation Metrics:\n",
      "                 Metric     Value\n",
      "0              F1 Score  0.531597\n",
      "1             Precision  0.581625\n",
      "2                Recall  0.515757\n",
      "3  Exact Match Accuracy  0.083053\n",
      "4          Hamming Loss  0.123906\n",
      "5         Jaccard Score  0.369899\n",
      "6              Hit Rate  0.831650\n",
      "7               ROC AUC  0.848243\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, hamming_loss, jaccard_score, roc_auc_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def predict_genres_with_naives(classifier, vectorizer, df_source, mlb, id2label, threshold=0.5):\n",
    "    # Vectorize clean synopsis\n",
    "    X = vectorizer.transform(df_source['clean_synopsis'])\n",
    "    y_true = mlb.transform(df_source['genres'])\n",
    "\n",
    "    # Predict probabilities and apply threshold\n",
    "    probabilities = classifier.predict_proba(X)\n",
    "    probabilities = np.array(probabilities)  # list of arrays → array\n",
    "    if isinstance(probabilities, list):  # OneVsRestClassifier returns list of arrays\n",
    "        probabilities = np.vstack([p[:, 1] for p in probabilities]).T\n",
    "    predictions = (probabilities >= threshold).astype(int)\n",
    "\n",
    "    # Decode predicted genres using id2label\n",
    "    predicted_genres = []\n",
    "    for row in predictions:\n",
    "        genres = [id2label[i] for i, val in enumerate(row) if val == 1]\n",
    "        predicted_genres.append(genres)\n",
    "\n",
    "    # === Calculate metrics ===\n",
    "    f1 = f1_score(y_true, predictions, average='macro')\n",
    "    precision = precision_score(y_true, predictions, average='macro')\n",
    "    recall = recall_score(y_true, predictions, average='macro')\n",
    "    accuracy = accuracy_score(y_true, predictions)\n",
    "    hamming = hamming_loss(y_true, predictions)\n",
    "    jaccard = jaccard_score(y_true, predictions, average='macro')\n",
    "    hit_rate = (np.logical_and(y_true, predictions).sum(axis=1) > 0).mean()\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(y_true, probabilities, average='macro')\n",
    "    except ValueError:\n",
    "        roc_auc = np.nan\n",
    "\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Metric': [\n",
    "            'F1 Score', 'Precision', 'Recall', 'Exact Match Accuracy',\n",
    "            'Hamming Loss', 'Jaccard Score', 'Hit Rate', 'ROC AUC'\n",
    "        ],\n",
    "        'Value': [\n",
    "            f1, precision, recall, accuracy,\n",
    "            hamming, jaccard, hit_rate, roc_auc\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    # Build result DataFrame\n",
    "    result_df = pd.DataFrame({\n",
    "        \"synopsis\": df_source[\"synopsis\"].values,\n",
    "        \"true_genres\": df_source[\"genres\"].values,\n",
    "        \"predicted_genres\": predicted_genres\n",
    "    })\n",
    "\n",
    "    print(\"\\n📊 Evaluation Metrics:\")\n",
    "    print(metrics_df)\n",
    "\n",
    "    return result_df, metrics_df, probabilities, y_true, predictions\n",
    "\n",
    "print(\"0.5 Thresh\")\n",
    "use_thresh=0.5\n",
    "id2label = {i: label for i, label in enumerate(mlb.classes_)}\n",
    "#df_train_results, train_metrics, train_prob, train_labels, train_pred  = predict_genres_with_naives(classifier, vectorizer, df_train, mlb, id2label, threshold=use_thresh)\n",
    "df_val_results, val_metrics, val_prob, val_labels, val_pred = predict_genres_with_naives(classifier, vectorizer, df_val, mlb, id2label, threshold=use_thresh)\n",
    "df_test_results, test_metrics, test_prob, test_labels, test_pred = predict_genres_with_naives(classifier, vectorizer, df_test, mlb, id2label, threshold=use_thresh)\n",
    "\n",
    "\n",
    "# print(\"prior Thresh\")\n",
    "# use_thresh=prior_threshold\n",
    "# df_test_results, test_metrics, test_prob, test_labels, test_pred = predict_genres_with_naives(classifier, vectorizer, df_test, mlb, id2label, threshold=use_thresh)\n",
    "\n",
    "print(\"F1 Thresh\")\n",
    "optimised_thresh=optimize_thresholds_with_precision_constraint(val_prob,val_labels)\n",
    "use_thresh=optimised_thresh\n",
    "df_test_results, test_metrics, test_prob, test_labels, test_pred = predict_genres_with_naives(classifier, vectorizer, df_test, mlb, id2label, threshold=use_thresh)\n",
    "\n",
    "# print(\"MCC Thresh\")\n",
    "# optimised_thresh=optimize_thresholds_with_mcc_constraint(val_prob,val_labels)\n",
    "# use_thresh=optimised_thresh\n",
    "# df_test_results, test_metrics, test_prob, test_labels, test_pred = predict_genres_with_naives(classifier, vectorizer, df_test, mlb, id2label, threshold=use_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "44ad1351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎬 Predicted Genres for New Synopses:\n",
      "                                            synopsis  \\\n",
      "0  A young boy discovers his hidden powers and jo...   \n",
      "1  A romantic comedy where two strangers meet at ...   \n",
      "2                           Love girl school romance   \n",
      "\n",
      "                   predicted_genres  \n",
      "0                       [Adventure]  \n",
      "1  [Comedy, Romance, Slice of Life]  \n",
      "2                 [Romance, School]  \n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "synopsis",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "predicted_genres",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "e109b04f-7bbd-4024-83ba-f7438759aa90",
       "rows": [
        [
         "0",
         "A young boy discovers his hidden powers and joins a group of heroes to fight evil forces.",
         "['Adventure']"
        ],
        [
         "1",
         "A romantic comedy where two strangers meet at a cafe and end up falling in love despite their differences.",
         "['Comedy', 'Romance', 'Slice of Life']"
        ],
        [
         "2",
         "Love girl school romance",
         "['Romance', 'School']"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>synopsis</th>\n",
       "      <th>predicted_genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A young boy discovers his hidden powers and jo...</td>\n",
       "      <td>[Adventure]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A romantic comedy where two strangers meet at ...</td>\n",
       "      <td>[Comedy, Romance, Slice of Life]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Love girl school romance</td>\n",
       "      <td>[Romance, School]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            synopsis  \\\n",
       "0  A young boy discovers his hidden powers and jo...   \n",
       "1  A romantic comedy where two strangers meet at ...   \n",
       "2                           Love girl school romance   \n",
       "\n",
       "                   predicted_genres  \n",
       "0                       [Adventure]  \n",
       "1  [Comedy, Romance, Slice of Life]  \n",
       "2                 [Romance, School]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def predict_new_synopses_naives(classifier, vectorizer, new_synopses, id2label, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Predict genres for a list of new synopses using the trained Naive Bayes model.\n",
    "    \"\"\"\n",
    "    # Vectorize the input synopses\n",
    "    X = vectorizer.transform(new_synopses)\n",
    "\n",
    "    # Predict probabilities and apply threshold\n",
    "    probabilities = classifier.predict_proba(X)\n",
    "    probabilities = np.array(probabilities)  # list of arrays → array\n",
    "    if isinstance(probabilities, list):  # OneVsRestClassifier returns list of arrays\n",
    "        probabilities = np.vstack([p[:, 1] for p in probabilities]).T\n",
    "    predictions = (probabilities >= threshold).astype(int)\n",
    "\n",
    "    # Decode predicted genres using id2label\n",
    "    predicted_genres = []\n",
    "    for row in predictions:\n",
    "        genres = [id2label[i] for i, val in enumerate(row) if val == 1]\n",
    "        predicted_genres.append(genres)\n",
    "\n",
    "    # Build result DataFrame\n",
    "    result_df = pd.DataFrame({\n",
    "        \"synopsis\": new_synopses,\n",
    "        \"predicted_genres\": predicted_genres\n",
    "    })\n",
    "\n",
    "    print(\"\\n🎬 Predicted Genres for New Synopses:\")\n",
    "    print(result_df)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "# Example usage\n",
    "new_synopses = [\n",
    "    \"A young boy discovers his hidden powers and joins a group of heroes to fight evil forces.\",\n",
    "    \"A romantic comedy where two strangers meet at a cafe and end up falling in love despite their differences.\",\n",
    "    \"Love girl school romance\"\n",
    "]\n",
    "\n",
    "# Predict genres for the new synopses\n",
    "predicted_df = predict_new_synopses_naives(classifier, vectorizer, new_synopses, id2label, threshold=0.5)\n",
    "display(predicted_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5025194f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Thresh\n",
      "Label 0: Best threshold = 0.37, F1 = 0.6957\n",
      "Label 1: Best threshold = 0.28, F1 = 0.6050\n",
      "Label 2: Best threshold = 0.37, F1 = 0.6675\n",
      "Label 3: Best threshold = 0.28, F1 = 0.5101\n",
      "Label 4: Best threshold = 0.37, F1 = 0.6056\n",
      "Label 5: Best threshold = 0.12, F1 = 0.6154\n",
      "Label 6: Best threshold = 0.14, F1 = 0.5578\n",
      "Label 7: Best threshold = 0.11, F1 = 0.6057\n",
      "Label 8: Best threshold = 0.13, F1 = 0.4706\n",
      "Label 9: Best threshold = 0.14, F1 = 0.5253\n",
      "Label 10: Best threshold = 0.23, F1 = 0.6062\n",
      "Label 11: Best threshold = 0.41, F1 = 0.6296\n",
      "Label 12: Best threshold = 0.29, F1 = 0.6721\n",
      "Label 13: Best threshold = 0.17, F1 = 0.2727\n",
      "Label 14: Best threshold = 0.16, F1 = 0.3864\n",
      "Label 15: Best threshold = 0.22, F1 = 0.4651\n",
      "Label 16: Best threshold = 0.27, F1 = 0.5349\n",
      "Label 17: Best threshold = 0.17, F1 = 0.8049\n",
      "Label 18: Best threshold = 0.12, F1 = 0.2857\n",
      "Label 19: Best threshold = 0.23, F1 = 0.5962\n",
      "\n",
      "📊 Evaluation Metrics:\n",
      "                 Metric     Value\n",
      "0              F1 Score  0.531597\n",
      "1             Precision  0.581625\n",
      "2                Recall  0.515757\n",
      "3  Exact Match Accuracy  0.083053\n",
      "4          Hamming Loss  0.123906\n",
      "5         Jaccard Score  0.369899\n",
      "6              Hit Rate  0.831650\n",
      "7               ROC AUC  0.848243\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 Thresh\")\n",
    "optimised_thresh=optimize_thresholds_with_precision_constraint(val_prob,val_labels)\n",
    "use_thresh=optimised_thresh\n",
    "df_test_results, test_metrics, test_prob, test_labels, test_pred = predict_genres_with_naives(classifier, vectorizer, df_test, mlb, id2label, threshold=use_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac4aa41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Evaluation Metrics:\n",
      "                 Metric     Value\n",
      "0              F1 Score  0.540043\n",
      "1             Precision  0.554933\n",
      "2                Recall  0.540256\n",
      "3  Exact Match Accuracy  0.098655\n",
      "4          Hamming Loss  0.123038\n",
      "5         Jaccard Score  0.379643\n",
      "6              Hit Rate  0.848655\n",
      "7               ROC AUC  0.821518\n",
      "\n",
      "📊 Evaluation Metrics:\n",
      "                 Metric     Value\n",
      "0              F1 Score  0.529547\n",
      "1             Precision  0.549325\n",
      "2                Recall  0.530849\n",
      "3  Exact Match Accuracy  0.075196\n",
      "4          Hamming Loss  0.127778\n",
      "5         Jaccard Score  0.367733\n",
      "6              Hit Rate  0.835017\n",
      "7               ROC AUC  0.825164\n"
     ]
    }
   ],
   "source": [
    "use_thresh=0.5\n",
    "id2label = {i: label for i, label in enumerate(mlb.classes_)}\n",
    "#df_train_results, train_metrics, train_prob, train_labels, train_pred  = predict_genres_with_naives(classifier, vectorizer, df_train, mlb, id2label, threshold=use_thresh)\n",
    "df_val_results, val_metrics, val_prob, val_labels, val_pred = predict_genres_with_naives(classifier, vectorizer, df_val, mlb, id2label, threshold=use_thresh)\n",
    "df_test_results, test_metrics, test_prob, test_labels, test_pred = predict_genres_with_naives(classifier, vectorizer, df_test, mlb, id2label, threshold=use_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4204b1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Action       0.77      0.82      0.79      2227\n",
      "    Adventure       0.71      0.89      0.79      1552\n",
      "       Comedy       0.81      0.88      0.84      2913\n",
      "        Drama       0.77      0.87      0.82      1473\n",
      "      Fantasy       0.83      0.82      0.83      1686\n",
      "   Historical       0.67      0.97      0.79       529\n",
      "         Kids       0.66      0.98      0.79       594\n",
      "        Mecha       0.63      0.95      0.75       543\n",
      "        Music       0.42      0.99      0.59       366\n",
      "      Mystery       0.72      0.97      0.83       474\n",
      "      Romance       0.72      0.85      0.78      1195\n",
      "       School       0.63      0.93      0.75       968\n",
      "       Sci-Fi       0.87      0.79      0.83      1419\n",
      "       Seinen       0.97      0.81      0.88       507\n",
      "       Shoujo       0.95      0.87      0.90       402\n",
      "      Shounen       0.77      0.90      0.83      1141\n",
      "Slice of Life       0.87      0.76      0.81      1004\n",
      "       Sports       0.70      0.98      0.82       361\n",
      "  Super Power       0.88      0.81      0.85       356\n",
      " Supernatural       0.79      0.89      0.84       909\n",
      "\n",
      "    micro avg       0.75      0.87      0.81     20619\n",
      "    macro avg       0.76      0.89      0.81     20619\n",
      " weighted avg       0.77      0.87      0.81     20619\n",
      "  samples avg       0.76      0.87      0.78     20619\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Action       0.65      0.73      0.69       278\n",
      "    Adventure       0.55      0.67      0.60       205\n",
      "       Comedy       0.64      0.65      0.64       364\n",
      "        Drama       0.51      0.44      0.47       184\n",
      "      Fantasy       0.63      0.51      0.56       214\n",
      "   Historical       0.53      0.59      0.56        66\n",
      "         Kids       0.52      0.60      0.56        75\n",
      "        Mecha       0.48      0.71      0.57        69\n",
      "        Music       0.36      0.57      0.44        46\n",
      "      Mystery       0.58      0.57      0.57        60\n",
      "      Romance       0.53      0.61      0.57       144\n",
      "       School       0.51      0.76      0.61       121\n",
      "       Sci-Fi       0.67      0.58      0.62       178\n",
      "       Seinen       1.00      0.17      0.29        70\n",
      "       Shoujo       0.83      0.18      0.29        57\n",
      "      Shounen       0.45      0.41      0.43       142\n",
      "Slice of Life       0.66      0.34      0.45       125\n",
      "       Sports       0.69      0.84      0.76        45\n",
      "  Super Power       0.83      0.11      0.20        45\n",
      " Supernatural       0.61      0.54      0.57       113\n",
      "\n",
      "    micro avg       0.58      0.57      0.57      2601\n",
      "    macro avg       0.61      0.53      0.52      2601\n",
      " weighted avg       0.60      0.57      0.56      2601\n",
      "  samples avg       0.56      0.58      0.53      2601\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Action       0.62      0.70      0.66       279\n",
      "    Adventure       0.48      0.63      0.54       183\n",
      "       Comedy       0.65      0.63      0.64       364\n",
      "        Drama       0.44      0.43      0.43       184\n",
      "      Fantasy       0.67      0.59      0.63       208\n",
      "   Historical       0.48      0.59      0.53        66\n",
      "         Kids       0.45      0.49      0.47        74\n",
      "        Mecha       0.45      0.59      0.51        75\n",
      "        Music       0.40      0.67      0.50        46\n",
      "      Mystery       0.53      0.51      0.52        59\n",
      "      Romance       0.51      0.54      0.52       157\n",
      "       School       0.47      0.72      0.56       121\n",
      "       Sci-Fi       0.72      0.50      0.59       177\n",
      "       Seinen       0.81      0.19      0.31        69\n",
      "       Shoujo       0.46      0.12      0.19        49\n",
      "      Shounen       0.43      0.39      0.41       145\n",
      "Slice of Life       0.60      0.37      0.46       126\n",
      "       Sports       0.58      0.73      0.65        45\n",
      "  Super Power       0.75      0.07      0.12        44\n",
      " Supernatural       0.52      0.44      0.48       114\n",
      "\n",
      "    micro avg       0.55      0.54      0.54      2585\n",
      "    macro avg       0.55      0.49      0.49      2585\n",
      " weighted avg       0.57      0.54      0.53      2585\n",
      "  samples avg       0.53      0.54      0.49      2585\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\nlp_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\User\\anaconda3\\envs\\nlp_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\User\\anaconda3\\envs\\nlp_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(train_labels, train_pred, target_names=all_genres))\n",
    "print(classification_report(val_labels, val_pred, target_names=all_genres))\n",
    "print(classification_report(test_labels, test_pred, target_names=all_genres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c6815909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "synopsis",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "true_genres",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "predicted_genres",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "8b12a8ee-1f0e-432a-be0d-0e672c845ae9",
       "rows": [
        [
         "0",
         "The daily life of the Motsumoto family. The three sisters, Fuu, Suu, and Chii, follow what happens on a daily basis. Mother and Father have to deal with them sometimes, but they're used to it.",
         "['Comedy', 'Slice of Life']",
         "['Comedy', 'Romance', 'Slice of Life']"
        ],
        [
         "1",
         "The Soul Tree, the great source of our race.  But for its ultimate power and by those whose minds were blinded by it, it also became the catastrophic cause that had brought never-ending wars between the tribes. Tortured by the agonies of the wars, the leaders of the tribes finally came to a peace agreement that they would instead open a competition. Players, equipped with special watches and shields, compete against each other as winner’s tribe would be awarded with Materion, the sacred fruit of the Soul Tree.  These brave players, who throw themselves in this fierce fight, we call them the Runningman.",
         "['Action', 'Adventure', 'Kids']",
         "['Action', 'Adventure', 'Fantasy']"
        ],
        [
         "2",
         "Fairies living in a fluffy forest, where both flowers and trees are fluffy. Follow a witch's trouble-maker apprentices Pui Pui and Muu Muu.",
         "['Fantasy', 'Kids']",
         "['Comedy', 'Fantasy', 'Kids', 'Shoujo', 'Slice of Life']"
        ],
        [
         "3",
         "A cyborg warrior from an ancient Antarctic kingdom awakes 30000 years later from an accidental hibernation to find the Earth changed and an old alien enemy on the verge of invasion. It's up to Guyslugger to use his ancient technology to defeat the aliens.",
         "['Action', 'Mecha', 'Sci-Fi']",
         "['Action', 'Adventure', 'Mecha', 'Sci-Fi', 'Shounen']"
        ],
        [
         "4",
         "The 2018 LINE sticker set Poccolies is inspiring a series of anime shorts. The story of the sticker set is that a positive and honest boy named Patsuhiko lives on Pokkori Island, along with the shrewd and mysterious Ham, and a reliable older brother figure named Kangaroo. The sticker set follows their daily lives.",
         "['Kids', 'Slice of Life']",
         "['Comedy', 'Slice of Life']"
        ],
        [
         "5",
         "General of the Three Kingdoms, Kongming had struggled his whole life, facing countless battles that made him into the accomplished strategist he was. So on his deathbed, he wished only to be reborn into a peaceful world... and was sent straight to modern-day party-central, Tokyo! Can even a brilliant strategist like Kongming adapt to the wild beats and even wilder party people?!",
         "['Comedy']",
         "['Action', 'Shounen']"
        ],
        [
         "6",
         "This show consists of shorts starring 7 characters created and voiced by the voice actors of the variety show \"Seiyuu Danshi desu ga...?\". The anime will be a slapstick comedy that follows seven spirits that come to the modern world.",
         "['Comedy', 'Supernatural']",
         "['Comedy', 'Kids']"
        ],
        [
         "7",
         "The supreme Gods who had too much free time created the ultimate brain games \"Play of the Gods.\" Former Goddess Leche awoke from a long slumber and declared to the world, \"Bring forth the person who is the best in games in this era!\" Fay is nominated to represent humanity as the \"best rookie in recent years.\"  The \"Game of the Gods\" that is about to begin between the two may be a little too difficult, as there has yet to be a victor throughout human history, because Gods are capricious, very unreasonable, and sometimes completely incomprehensible. However, given the nature of the games, it would be a waste not to have a good time and play with all of one's heart! The ultimate brain battles of a genius gamer boy, a former Goddess, and friends begin!",
         "['Fantasy']",
         "['Action', 'Fantasy']"
        ],
        [
         "8",
         "Technoroid: Overmind is set in the Entertainment Tower Babel, a new hope found by those who have lost the joy of light as humanity's activities are restricted due to the large-scale climate change caused by the expanded sun. The anime depicts unique units and characters fighting for the top of Babel, pursuing emotions that move people and androids through performances.",
         "['Music']",
         "['Action']"
        ],
        [
         "9",
         "A young woman aims to become a famous fashion designer.",
         "['Romance', 'Shoujo']",
         "['Kids', 'Romance']"
        ],
        [
         "10",
         "Say hi to Tayo's new friend - Titipo! Train Center's new born little train Titipo has just passed the driving examination and is prepared to work at the Train Village. Although Titipo dreams of becoming the best train in the world, his curious yet random personality catches him in unforeseen events and troubles everyday. Titipo expands his experience in the greater world and befriends Genie, Diesel, and other little trains. Will Titipo achieve his dream of becoming the best train? Come join the railroad journey and meet Titipo and the little train friends.",
         "['Kids']",
         "['Comedy', 'Slice of Life']"
        ],
        [
         "11",
         "The series follows Officer Black Cat's adventures around the forest neighbourhood, apprehending criminals, dealing justice, and solving crimes.",
         "['Action', 'Adventure', 'Comedy', 'Kids']",
         "['Adventure', 'Comedy', 'Kids']"
        ],
        [
         "12",
         "The hero of Tensei shitara Ken deshita differs from your standard otherworldly protagonist in that he is reincarnated as a sword! Beginning his quest by spawning in the middle of a beast-ridden forest, he encounters an injured girl frantically fleeing for her life. Saving her from her assailants, the pair acquaint themselves, and the girl introduces herself as Fran. She bears a heavy past, having endured the enslavement and maltreatment of her tribe, the Black Cats.  As the hero is unable to remember the name from his past life, the young and tenacious Fran bestows him the name \"Shishou\" and becomes his wielder. Thereafter, Shishou and Fran become a formidable team, embarking on quests to liberate the oppressed and exact justice!",
         "['Action', 'Fantasy']",
         "['Action', 'Adventure', 'Fantasy']"
        ],
        [
         "13",
         "If a girl teases you, that means she likes you!  Unfortunately, Akiteru knows from experience that isn't the case. Because every girl he interacts with shows him nothing but scorn, and he's not scored a single date from it! Luckily, he's more concerned with securing a spot for him and his game-development buddies at his uncle's business.  But when his uncle throws him a condition that involves playing the part of his daughter's boyfriend, Akiteru has no choice but to take it. What will his best friend's sister Iroha, who bullies him relentlessly, think of the news?",
         "['Comedy', 'Romance', 'School']",
         "['Comedy', 'Drama', 'Romance']"
        ],
        [
         "14",
         "The second season of . SBS took over broadcasting the show. The art style has been changed for a more modern anime-esque appearance and some voice actors did not reprise their character's roles.",
         "['Kids', 'Sci-Fi']",
         "['Comedy', 'Slice of Life']"
        ],
        [
         "15",
         "Hitori Gotou is a high school girl who's starting to learn to play the guitar because she dreams of being in a band, but she's so shy that she hasn't made a single friend. However, her dream might come true after she meets Nijika Ijichi, a girl who plays drums and is looking for a new guitarist for her band.",
         "['Comedy', 'Music', 'Slice of Life']",
         "['Comedy', 'Drama', 'Music', 'Romance', 'Slice of Life']"
        ],
        [
         "16",
         "The anime's story centers on a cat named Maru, adopted by a girl named Anna from a shelter in Matsuyama city. Loved and well fed by the family, Maru gets rounder and fatter every day, spending most of his day sitting by the window and looking at the garden outside. When the family gets a new cat named Cerisier and begins doting on it, Maru gets jealous. In a fight with Cerisier, Maru is hurt by the family's words to him, and follows the advice of another cat to leave and see the world.",
         "['Slice of Life']",
         "['Comedy']"
        ],
        [
         "17",
         "TV anime based on San-X's new series of mascot characters \"Chickip Dancers.\" The main characters in the anime will be the apprehensive but curious bone-in chicken Hone Chicken, and the dancing instructor frog Skip Gaeru, who travels by dancing.",
         "['Slice of Life']",
         "['Comedy', 'Kids']"
        ],
        [
         "18",
         "A Chinese prince meets a regular civilian during his travels and quickly falls in love. They marry and have a daughter, but the prince is soon separated from them during a rebellion. Many years later, the prince has become emperor and locates his lost daughter. She comes to live with him, but unfortunately has picked up several unrefined habits during her times as a civilian.",
         "['Comedy', 'Historical', 'Kids']",
         "['Comedy', 'Historical', 'Romance']"
        ],
        [
         "19",
         "The anime follows the frogs Kekkero and Ke who try to find their 998 other siblings.",
         "['Comedy']",
         "['Kids', 'Slice of Life']"
        ],
        [
         "20",
         "The series follows a young girl named Shina who hopes to become the world's best DJ, and is interested in new sounds. Shina explores a mysterious world filled with Otoppe, strange creatures capable of unique sounds.",
         "['Fantasy', 'Kids', 'Music']",
         "['Fantasy']"
        ],
        [
         "21",
         "Excellent student Iwakura Mitsumi has always dreamt about leaving her small town, going to a prestigious university, and making positive change in the world. But she's so focused on reaching her goals that she's not prepared for the very different (and overwhelming) city life that awaits her in a Tokyo high school. Luckily, she makes fast friends with Shima Sousuke, a handsome classmate who's as laid-back as she is over-prepared. Can this naive country girl make it big in Tokyo with Sousuke by her side?",
         "['School', 'Seinen', 'Slice of Life']",
         "['Slice of Life']"
        ],
        [
         "22",
         "It follows the fan favorite character Vandyne as his hidden secrets are revealed. Unlike the reboot, which exclusively uses 3DCG visuals, this series is like the earlier entries and is animated with 2D and 3D visuals.  The mini-series is part of a new promotional campaign from Sono Kong. The Korean toy manufacturer will launch four new mechanimals this month at retail.",
         "['Adventure', 'Kids', 'Mecha']",
         "[]"
        ],
        [
         "23",
         "The mischievous antics of a ghost in an ancient village.",
         "['Supernatural']",
         "['Comedy', 'Fantasy', 'Kids']"
        ],
        [
         "24",
         "One day, a gamer played video games until he fell asleep...and when he woke up, he found himself in the game world—as a skeleton! Equipped with the powerful weapons and armor of his avatar but stuck with its frightening skeletal appearance, Arc has to find a place for himself in this new, fantastical land. All his hopes for a quiet life are dashed when he crosses paths with a beautiful elven warrior, setting him on a journey full of conflict and adventure.",
         "['Action', 'Fantasy']",
         "['Action', 'Adventure', 'Fantasy']"
        ],
        [
         "25",
         "The anime is based on Kazuo Hara's comedy manga in which mascot characters live and work among humans. Agencies have been set up to train mascots to babysit children and then to place the mascots within families. Noramimi is one such mascot at the Hello Kids branch office #59. Unfortunately, no family wants to adopt a mascot born from a demon (oni) family, so he is stuck living at the agency.  Source: ANN, Moon Phase",
         "['Comedy']",
         "['Comedy']"
        ],
        [
         "26",
         "The series of \"warm and soothing\" anime shorts will follow a cat who is suddenly resurrected from the grave and begins to wander around town. Despite being a zombie, the cat is able to get all the townsfolk to fall in love with it.",
         "['Comedy']",
         "['Comedy']"
        ],
        [
         "27",
         "Shoot for the stars! I'm going to be the country's number one alchemist!  When young girl Sarasa graduated from the Royal Alchemist Academy, her teacher gifted her a house for her to set up shop. Aiming to become a masterclass alchemist, she gathers materials herself, experiments and operates a business. In her very own atelier, Sarasa indulges in a slow and relaxed alchemist life!",
         "['Adventure', 'Fantasy', 'Slice of Life']",
         "['Comedy', 'Fantasy']"
        ],
        [
         "28",
         "Based on Otomate's puzzle role-playing game.  A medical student named Shiina and nine male partners are trapped in a certain dimensional realm with many ancient texts and an enormous mysterious clock. Together, they must find a way to escape by uncovering clues before the clock strikes \"13.\"",
         "['Mystery', 'Romance', 'Supernatural']",
         "['Fantasy', 'Mystery']"
        ],
        [
         "29",
         "An anime/documentary series about athletes present by NHK.  The first episode adapts material from Tomoyoshi Itou and Shingo Morita's Weekly Young Jump biographical manga (Geniuses Without Glory)—specifically the story about Hironoshin Furuhashi, the swimmer also known as \"the flying fish of Fujiyama.\" The episode also includes interviews with Olympic swimmer Kousuke Kitajima and other Japanese swimmers about the how Furuhashi changed the Japanese competitive swimming world, as well as what sort of training is required to be an Olympic swimmer.",
         "['Sports']",
         "['Comedy', 'Drama', 'Sports']"
        ],
        [
         "30",
         "A story of the adventures of Robby and Kerobby along with their other friends.",
         "['Comedy', 'Kids']",
         "['Adventure', 'Comedy', 'Kids']"
        ],
        [
         "31",
         "Eiyuu Densetsu: Sen no Kiseki centers around Rean Schwarzer, a professor at Thors Military Academy in the Erebonian Empire. The anime's story will focus on the western part of the Zemurian continent featured in the games.",
         "['Action']",
         "[]"
        ],
        [
         "32",
         "A little ghost girl gets worries when Ms. Fushihara, a corporate slave, is working till midnight, and tries to make her go home. While saying \"Leave now~,\" the ghost girl helps and brings her refreshments, healing Ms. Fushihara's heart with her preciousness. Be healed by the heartwarming daily life of the cute little ghost and the corporate slave Ms. Fushihara.",
         "['Comedy', 'Shounen', 'Slice of Life', 'Supernatural']",
         "['Comedy', 'Slice of Life']"
        ],
        [
         "33",
         "The story follows as Tochi and Milo travel the world in search of new Kimchi Pong to save their homes and uncover the secrets behind these creatures.",
         "['Adventure', 'Fantasy', 'Kids']",
         "['Action', 'Adventure', 'Comedy', 'Fantasy', 'Sci-Fi', 'Shounen']"
        ],
        [
         "34",
         "On planet Kirakira live two tribes: Senobi and Robot. Senobi, quiet and peacefully set, settle down in the forest. Robot comes from the desert and starts war to take control of afforested grounds. A young hero coming from Senobi tries to appease the whole situation.",
         "['Action', 'Adventure', 'Sci-Fi']",
         "['Action', 'Adventure', 'Fantasy', 'Sci-Fi']"
        ],
        [
         "35",
         "Urobe was a son of the great chief of Pyrimi, Africa. One day he hung on an airplane and came to Japan. Because of the cold and hunger, he fell on to the yard of Shishio’s house, and Shishio nursed him. Kurobe was very thankful for him and began to repay for his kindness. Kurobe dug a big hole in the yard.Every time he returns the favor, he threw a stone into the hole until stones would fill the hole.",
         "['Comedy']",
         "['Action', 'Adventure']"
        ],
        [
         "36",
         "It is the time of civil war. Zipangu is a country where people live together with gimmick warriors, a kind of super human robot. There, people and gimmick warriors struggle to seize power. Musashi, a Samurai gimmick warrior, departs to on a quest to become the best Samurai warrior. Musashi thrives in the series of battles, encountering with many heroes and villains including his lifelong rival, Kojiro, an expert swordsman.Later, Mushashi and Kojiro are sent by their General to escort the Princess, a granddaughter of the general. The princess is spoiled and difficult, so their journey becomes series of misadventures. Soon, they are caught up in a battle to seize control of the Country.",
         "['Action', 'Adventure', 'Mecha']",
         "['Action', 'Adventure', 'Historical', 'Shounen']"
        ],
        [
         "37",
         "The story is told by the cat-eyed boy, hated by humans and demons, who engages in tales of terror, including monsters and children.",
         "['Adventure', 'Seinen', 'Supernatural']",
         "['Fantasy', 'Shounen', 'Supernatural']"
        ],
        [
         "38",
         "In the city of Fuuto, criminals make use of USB-like devices called \"Gaia Memories\" to turn themselves into superpowered monsters known as \"Dopants,\" wreaking havoc in the otherwise peaceful city. However, there are also heroes who utilize the Gaia Memories to fight these criminals, one of whom is the self-proclaimed, hard-boiled detective Shoutarou Hidari. With the help of his witty partner Philip, the two transform into Kamen Rider W—the legendary hero of Fuuto city.  After the fall of Museum—the evil organisation responsible for many crimes in Fuuto—the production and distribution of Gaia Memories has halted. However, remnants of Gaia Memories still remain within society and are sold in the black market at high prices. Thus, the two heroes from Narumi Detective Agency are yet to have time to relax. Sights of Dopants still occur and the agency receives more and more clients who claim to experience supernatural phenomena.  Regardless of the arduous nature of the task, Kamen Rider W promises that those who hurt Fuuto will inevitably count up their sins.",
         "['Action', 'Drama', 'Mystery', 'Seinen', 'Supernatural']",
         "['Action', 'Mystery', 'Sci-Fi', 'Supernatural']"
        ],
        [
         "39",
         "Tonko House has partnered with Japanese stop-motion house \"dwarf\" and CG studio Megalis on the new project. Tsutsumi is the directing showrunner of a stop-motion/CGI animated TV series called “Oni,” about a human girl being raised by a mythical Japanese god.  Tonko House plans to show test footage of at its first-ever Tonko House Film Festival this spring in Tokyo.",
         "['Kids']",
         "['Kids']"
        ],
        [
         "40",
         "Nameko Forest gathers nameko from all over the world. They form the Nameko Universal Ranger (NUR) to convey the charm of the forest. It's an everyday life of inviting new nameko with unique personalities to the forests. What incident will happen today?",
         "['Comedy', 'Kids']",
         "['Comedy', 'Kids']"
        ],
        [
         "41",
         "The story tells the tale of Semi, a bright girl who goes in a magical time journey with the genius teacher Wai, in order to prevent the evil X from utilizing the powers of the magic cube for evil. Along the way, Semi and her math school friends run into history and math problems that they must solve with logic and wit.",
         "['Action', 'Comedy', 'Fantasy']",
         "['Adventure', 'Comedy', 'Historical']"
        ],
        [
         "42",
         "An NHK toddler's anime following a Spoon Princess and other kitchen themed characters.",
         "['Adventure', 'Kids']",
         "['Kids']"
        ],
        [
         "43",
         "The hero of Wansa-kun is Wansa, a puppy who is sold for a pittance, then escapes, and spends much of the rest of the series looking for his mother.",
         "['Comedy']",
         "['Adventure']"
        ],
        [
         "44",
         "Japan has 47 prefectures and each one has a guardian spirit called a Dochamon. follows guardian spirits in training to one day take over the jobs of their elders. But these juniors have a lot of growing up to do before they graduate!",
         "['Comedy', 'Kids']",
         "['Comedy', 'Supernatural']"
        ],
        [
         "45",
         "G.G. Bonds enters the realm of dreams to stop evil's power from growing. They must get the citizens of Crystal City to remember their dreams so that the 5 element powers can recharge.",
         "['Kids', 'Sci-Fi', 'Super Power']",
         "['Action', 'Adventure', 'Fantasy', 'Sci-Fi']"
        ],
        [
         "46",
         "Three oni-kids who, through the power of the onipan (a portmanteau of \"oni\" and \"pantsu\") become human to help fix the relationship between humans and oni. The three girls transfer into a normal Tokyo high school to aid in their task and help fix their image by revitalizing the town, sometimes jumping headfirst into school events, and other times ... becoming idols!",
         "['Comedy', 'Fantasy']",
         "['Comedy']"
        ],
        [
         "47",
         "The anime centers on Katsuko Yoshida, the cousin of Eagle Talon's Yoshida-kun, and an employee in Kemonomichi Electronics' \"special general affairs\" section. She educates her poorly informed colleagues about their misunderstandings of Sustainable Development Goals, the United Nations-backed goals for member nations to attain a sustainable future.",
         "['Comedy']",
         "['Comedy']"
        ],
        [
         "48",
         "The \"home comedy\" centers on the mischievous boy Rikkun and his eccentric family.",
         "['Comedy', 'Seinen']",
         "['Comedy', 'Slice of Life']"
        ],
        [
         "49",
         "St. Muse Academy: the place for the \"sound of the spirits.\" In order for people to live pleasantly among the sound, there is an academy where people learn to balance and control sound. Now, the five failing students receive a special mission...",
         "['Comedy', 'Music']",
         "[]"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 891
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>synopsis</th>\n",
       "      <th>true_genres</th>\n",
       "      <th>predicted_genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The daily life of the Motsumoto family. The th...</td>\n",
       "      <td>[Comedy, Slice of Life]</td>\n",
       "      <td>[Comedy, Romance, Slice of Life]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Soul Tree, the great source of our race.  ...</td>\n",
       "      <td>[Action, Adventure, Kids]</td>\n",
       "      <td>[Action, Adventure, Fantasy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fairies living in a fluffy forest, where both ...</td>\n",
       "      <td>[Fantasy, Kids]</td>\n",
       "      <td>[Comedy, Fantasy, Kids, Shoujo, Slice of Life]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A cyborg warrior from an ancient Antarctic kin...</td>\n",
       "      <td>[Action, Mecha, Sci-Fi]</td>\n",
       "      <td>[Action, Adventure, Mecha, Sci-Fi, Shounen]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 2018 LINE sticker set Poccolies is inspiri...</td>\n",
       "      <td>[Kids, Slice of Life]</td>\n",
       "      <td>[Comedy, Slice of Life]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>A series of four animated prequels to Street F...</td>\n",
       "      <td>[Action]</td>\n",
       "      <td>[Action, Drama, Mecha, Shounen]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>According to HMV, the DVD &amp; Blu-ray volume 7 o...</td>\n",
       "      <td>[Comedy, Seinen, Sports]</td>\n",
       "      <td>[Comedy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>Lucius ends up in a space station, where he ex...</td>\n",
       "      <td>[Comedy, Seinen]</td>\n",
       "      <td>[Comedy, Historical, Sci-Fi, Seinen]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>The \"Megumi and Taiyou\" commercial depicts the...</td>\n",
       "      <td>[Romance, Slice of Life]</td>\n",
       "      <td>[Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>Kiki is a 17-year-old high school witch living...</td>\n",
       "      <td>[Romance, Slice of Life]</td>\n",
       "      <td>[Comedy, Drama, Romance]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              synopsis  \\\n",
       "0    The daily life of the Motsumoto family. The th...   \n",
       "1    The Soul Tree, the great source of our race.  ...   \n",
       "2    Fairies living in a fluffy forest, where both ...   \n",
       "3    A cyborg warrior from an ancient Antarctic kin...   \n",
       "4    The 2018 LINE sticker set Poccolies is inspiri...   \n",
       "..                                                 ...   \n",
       "886  A series of four animated prequels to Street F...   \n",
       "887  According to HMV, the DVD & Blu-ray volume 7 o...   \n",
       "888  Lucius ends up in a space station, where he ex...   \n",
       "889  The \"Megumi and Taiyou\" commercial depicts the...   \n",
       "890  Kiki is a 17-year-old high school witch living...   \n",
       "\n",
       "                   true_genres                                predicted_genres  \n",
       "0      [Comedy, Slice of Life]                [Comedy, Romance, Slice of Life]  \n",
       "1    [Action, Adventure, Kids]                    [Action, Adventure, Fantasy]  \n",
       "2              [Fantasy, Kids]  [Comedy, Fantasy, Kids, Shoujo, Slice of Life]  \n",
       "3      [Action, Mecha, Sci-Fi]     [Action, Adventure, Mecha, Sci-Fi, Shounen]  \n",
       "4        [Kids, Slice of Life]                         [Comedy, Slice of Life]  \n",
       "..                         ...                                             ...  \n",
       "886                   [Action]                 [Action, Drama, Mecha, Shounen]  \n",
       "887   [Comedy, Seinen, Sports]                                        [Comedy]  \n",
       "888           [Comedy, Seinen]            [Comedy, Historical, Sci-Fi, Seinen]  \n",
       "889   [Romance, Slice of Life]                                       [Romance]  \n",
       "890   [Romance, Slice of Life]                        [Comedy, Drama, Romance]  \n",
       "\n",
       "[891 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#display(df_train_results)\n",
    "# display(df_val_results)\n",
    "display(df_test_results)\n",
    "df_test_results.to_csv(\"Predict TFIDF MNB.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea782537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: ROC AUC = 0.8501\n",
      "Adventure: ROC AUC = 0.8284\n",
      "Comedy: ROC AUC = 0.7777\n",
      "Drama: ROC AUC = 0.7570\n",
      "Fantasy: ROC AUC = 0.8694\n",
      "Historical: ROC AUC = 0.9078\n",
      "Kids: ROC AUC = 0.8992\n",
      "Mecha: ROC AUC = 0.9172\n",
      "Music: ROC AUC = 0.8983\n",
      "Mystery: ROC AUC = 0.8603\n",
      "Romance: ROC AUC = 0.8250\n",
      "School: ROC AUC = 0.8688\n",
      "Sci-Fi: ROC AUC = 0.8958\n",
      "Seinen: ROC AUC = 0.7364\n",
      "Shoujo: ROC AUC = 0.8242\n",
      "Shounen: ROC AUC = 0.7312\n",
      "Slice of Life: ROC AUC = 0.8651\n",
      "Sports: ROC AUC = 0.9705\n",
      "Super Power: ROC AUC = 0.8221\n",
      "Supernatural: ROC AUC = 0.8602\n"
     ]
    }
   ],
   "source": [
    "roc_auc_per_genre = roc_auc_score(test_labels, test_prob, average=None)\n",
    "for label, auc in zip(all_genres, roc_auc_per_genre):\n",
    "    print(f\"{label}: ROC AUC = {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9fe02d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "0",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "7c116e8b-36ba-4de4-a9e7-65c5faa4ca73",
       "rows": [
        [
         "0",
         "0.850106589828285"
        ],
        [
         "1",
         "0.8284168441851132"
        ],
        [
         "2",
         "0.7776862606084618"
        ],
        [
         "3",
         "0.7570337002644364"
        ],
        [
         "4",
         "0.8694461651086834"
        ],
        [
         "5",
         "0.9077685950413223"
        ],
        [
         "6",
         "0.8991696715074928"
        ],
        [
         "7",
         "0.9172058823529412"
        ],
        [
         "8",
         "0.8982505788525856"
        ],
        [
         "9",
         "0.8603120925684485"
        ],
        [
         "10",
         "0.8250143181936513"
        ],
        [
         "11",
         "0.868836535365461"
        ],
        [
         "12",
         "0.895765085695295"
        ],
        [
         "13",
         "0.7363976162770197"
        ],
        [
         "14",
         "0.8242280285035629"
        ],
        [
         "15",
         "0.7312286216141259"
        ],
        [
         "16",
         "0.8651104886399003"
        ],
        [
         "17",
         "0.970527974783294"
        ],
        [
         "18",
         "0.8221262208865514"
        ],
        [
         "19",
         "0.8602248865406761"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.850107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.828417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.777686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.757034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.869446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.907769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.899170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.917206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.898251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.860312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.825014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.868837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.895765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.736398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.824228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.731229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.865110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.970528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.822126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.860225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0   0.850107\n",
       "1   0.828417\n",
       "2   0.777686\n",
       "3   0.757034\n",
       "4   0.869446\n",
       "5   0.907769\n",
       "6   0.899170\n",
       "7   0.917206\n",
       "8   0.898251\n",
       "9   0.860312\n",
       "10  0.825014\n",
       "11  0.868837\n",
       "12  0.895765\n",
       "13  0.736398\n",
       "14  0.824228\n",
       "15  0.731229\n",
       "16  0.865110\n",
       "17  0.970528\n",
       "18  0.822126\n",
       "19  0.860225"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df=pd.DataFrame(roc_auc_per_genre)\n",
    "display(df)\n",
    "df.to_csv('TFIDFMNB.csv', float_format='%.2f', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e513fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def mcc_per_label(y_true, y_pred, label_names=None):\n",
    "    n_labels = y_true.shape[1]\n",
    "    mcc_scores = []\n",
    "\n",
    "    for i in range(n_labels):\n",
    "        mcc = matthews_corrcoef(y_true[:, i], y_pred[:, i])\n",
    "        mcc_scores.append(mcc)\n",
    "\n",
    "    if label_names is None:\n",
    "        label_names = [f\"Label_{i}\" for i in range(n_labels)]\n",
    "\n",
    "    return pd.Series(mcc_scores, index=label_names, name=\"MCC\")\n",
    "\n",
    "MCC_labels=mcc_per_label(val_labels,val_pred,label_names=all_genres)\n",
    "display(MCC_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eeeab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\nlp_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from my_import import *\n",
    "df_train = pd.read_csv('df_train.csv')\n",
    "df_val = pd.read_csv('df_val.csv')\n",
    "df_test = pd.read_csv('df_test.csv')\n",
    "\n",
    "#Make sure the genre collumns is in lists not strings\n",
    "#NEED TO DO THIS EVERYTIME EXPORT DATASET\n",
    "df_train['genres'] = df_train['genres'].apply(lambda x: list(ast.literal_eval(x)))\n",
    "df_val['genres'] = df_val['genres'].apply(lambda x: list(ast.literal_eval(x)))\n",
    "df_test['genres'] = df_test['genres'].apply(lambda x: list(ast.literal_eval(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6014cd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df_train['clean_synopsis'] = df_train['synopsis'].apply(clean_text)\n",
    "df_val['clean_synopsis'] = df_val['synopsis'].apply(clean_text)\n",
    "df_test['clean_synopsis'] = df_test['synopsis'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90581c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instead of using a fixed threshold we compare it to the prior threshold from the train set\n",
    "def predict_using_prior_threshold(X, classifier, priors):\n",
    "    \"\"\"\n",
    "    Predicts genres using P(c|x) > P(c) as threshold logic.\n",
    "    - classifier: trained OneVsRestClassifier\n",
    "    - priors: array of prior probabilities (i.e., class proportions in y_train)\n",
    "    \"\"\"\n",
    "    probs = classifier.predict_proba(X)\n",
    "    # compare each prob with its class's prior\n",
    "    preds = (probs > priors).astype(int)\n",
    "    return preds\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856811ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MultiLabelBinarizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n",
      "\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m hamming_loss\n",
      "\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# from sklearn.feature_extraction.text import CountVectorizer\u001b[39;00m\n",
      "\u001b[1;32m----> 7\u001b[0m mlb\u001b[38;5;241m=\u001b[39m\u001b[43mMultiLabelBinarizer\u001b[49m()\n",
      "\u001b[0;32m      8\u001b[0m y_train \u001b[38;5;241m=\u001b[39m mlb\u001b[38;5;241m.\u001b[39mfit_transform(df_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenres\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;32m      9\u001b[0m priors \u001b[38;5;241m=\u001b[39m y_train\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MultiLabelBinarizer' is not defined"
     ]
    }
   ],
   "source": [
    "#Parameters that can be changed:\n",
    "#Number of wordds in vocublary\n",
    "#Class weighting\n",
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "mlb=MultiLabelBinarizer()\n",
    "y_train = mlb.fit_transform(df_train['genres'])\n",
    "priors = y_train.mean(axis=0)\n",
    "#display(y)\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\",max_features=10000,ngram_range=(1,4))\n",
    "X_train = vectorizer.fit_transform(df_train['clean_synopsis'])\n",
    "#display(X_train)\n",
    "#print(vectorizer.get_feature_names_out(),len(vectorizer.get_feature_names_out()))\n",
    "#print(X_train.toarray())\n",
    "\n",
    "y_val= mlb.transform(df_val['genres'])\n",
    "X_val = vectorizer.transform(df_val['clean_synopsis'])\n",
    "y_test= mlb.transform(df_test['genres'])\n",
    "X_test = vectorizer.transform(df_test['clean_synopsis'])\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "classifier = OneVsRestClassifier(MultinomialNB(alpha=0.1))#Already tried with balanced class but it is worse\n",
    "classifier.fit(X_train, y_train)                                    #At least when it is not balanced it can overfit the train class\n",
    "\n",
    "# from sklearn.metrics import classification_report\n",
    "#samples\tHow well did we predict each movie's genres?\t✅ Best for your task\n",
    "#micro\t    Overall genre prediction accuracy\t            ✅ Good for global view\n",
    "#macro\t    Equal focus on rare and frequent genres\t        ⚠️ Careful with imbalance\n",
    "#weighted\tGenre performance balanced by frequency\t        ✅ Fair but skew-sensitive\n",
    "#USE SAMPLES\n",
    "\n",
    "\n",
    "print(\"Report for Train dataset\")\n",
    "#threshold=0.08\n",
    "#y_pred_train=LR_OVA_prob(X_train,threshold,classifier)\n",
    "y_pred_train = predict_using_prior_threshold(X_train, classifier, priors)\n",
    "print_report(y_train,y_pred_train,\"samples avg\",\"f1-score\",mlb)\n",
    "jaccard = jaccard_score(y_train, y_pred_train, average='samples')\n",
    "print(\"Jaccard Similarity:\", jaccard)\n",
    "hr = hit_rate(y_train, y_pred_train)\n",
    "print(\"Hit Rate:\", hr)\n",
    "hl = hamming_loss(y_train, y_pred_train)\n",
    "print(\"Hamming Loss:\", hl)\n",
    "\n",
    "print(\"----------------------\")\n",
    "print(\"Report for Val dataset\")\n",
    "#y_pred_val=LR_OVA_prob(X_val,threshold,classifier)\n",
    "y_pred_val = predict_using_prior_threshold(X_val, classifier, priors)\n",
    "print_report(y_val,y_pred_val,\"samples avg\",\"f1-score\",mlb)\n",
    "jaccard = jaccard_score(y_val, y_pred_val, average='samples')\n",
    "print(\"Jaccard Similarity:\", jaccard)\n",
    "hr = hit_rate(y_val, y_pred_val)\n",
    "print(\"Hit Rate:\", hr)\n",
    "hl = hamming_loss(y_val, y_pred_val)\n",
    "print(\"Hamming Loss:\", hl)\n",
    "\n",
    "\n",
    "print(\"----------------------\")\n",
    "print(\"Report for Test dataset\")\n",
    "#y_pred_test=LR_OVA_prob(X_test,threshold,classifier)\n",
    "y_pred_test = predict_using_prior_threshold(X_test, classifier, priors)\n",
    "print_report(y_test,y_pred_test,\"samples avg\",\"f1-score\",mlb)\n",
    "jaccard = jaccard_score(y_test, y_pred_test, average='samples')\n",
    "print(\"Jaccard Similarity:\", jaccard)\n",
    "hr = hit_rate(y_val, y_pred_val)\n",
    "print(\"Hit Rate:\", hr)\n",
    "hl = hamming_loss(y_test, y_pred_test)\n",
    "print(\"Hamming Loss:\", hl)\n",
    "\n",
    "\n",
    "\n",
    "display(result_table(y_train,y_pred_train,df_train,mlb))\n",
    "display(result_table(y_val,y_pred_val,df_val,mlb))\n",
    "display(result_table(y_test,y_pred_test,df_test,mlb))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
