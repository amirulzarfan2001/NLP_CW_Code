{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca77bf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import nltk\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49810edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('df_train.csv')\n",
    "df_val = pd.read_csv('df_val.csv')\n",
    "df_test = pd.read_csv('df_test.csv')\n",
    "\n",
    "for df in [df_train, df_val, df_test]:\n",
    "    df['genres'] = df['genres'].apply(lambda x: list(ast.literal_eval(x)))\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [lemmatizer.lemmatize(t) for t in tokens if t.isalpha() and t not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "for df in [df_train, df_val, df_test]:\n",
    "    df['clean_synopsis'] = df['synopsis'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb028e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_texts = [text.split() for text in df_train['clean_synopsis']]\n",
    "w2v_model = Word2Vec(tokenized_texts, vector_size=100, window=5, min_count=2, workers=4)\n",
    "\n",
    "word2idx = {word: i+1 for i, word in enumerate(w2v_model.wv.index_to_key)}\n",
    "word2idx[\"<PAD>\"] = 0\n",
    "idx2word = {i: w for w, i in word2idx.items()}\n",
    "\n",
    "embedding_matrix = np.zeros((len(word2idx), 100))\n",
    "for word, idx in word2idx.items():\n",
    "    if word in w2v_model.wv:\n",
    "        embedding_matrix[idx] = w2v_model.wv[word]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d37dc0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_seq(text, word2idx, maxlen=300):\n",
    "    seq = [word2idx.get(word, 0) for word in text.split()]\n",
    "    return seq[:maxlen] + [0] * max(0, maxlen - len(seq))\n",
    "\n",
    "maxlen = 300\n",
    "df_train['seq'] = df_train['clean_synopsis'].apply(lambda x: text_to_seq(x, word2idx, maxlen))\n",
    "df_val['seq'] = df_val['clean_synopsis'].apply(lambda x: text_to_seq(x, word2idx, maxlen))\n",
    "df_test['seq'] = df_test['clean_synopsis'].apply(lambda x: text_to_seq(x, word2idx, maxlen))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "262a76c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "y_train = mlb.fit_transform(df_train['genres'])\n",
    "y_val = mlb.transform(df_val['genres'])\n",
    "y_test = mlb.transform(df_test['genres'])\n",
    "id2label = {i: label for i, label in enumerate(mlb.classes_)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "417ab305",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnimeDataset(Dataset):\n",
    "    def __init__(self, sequences, labels):\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.sequences[idx], dtype=torch.long), torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "\n",
    "train_dataset = AnimeDataset(df_train['seq'].tolist(), y_train)\n",
    "val_dataset = AnimeDataset(df_val['seq'].tolist(), y_val)\n",
    "test_dataset = AnimeDataset(df_test['seq'].tolist(), y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5acb804b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, embedding_matrix):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.tensor(embedding_matrix, dtype=torch.float32), freeze=True)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        _, (hidden, _) = self.lstm(embedded)\n",
    "        hidden = torch.cat((hidden[0], hidden[1]), dim=1)\n",
    "        output = self.fc(hidden)\n",
    "        return self.sigmoid(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ffc5073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.4034\n",
      "Epoch 2: Loss = 0.3748\n",
      "Epoch 3: Loss = 0.3513\n",
      "Epoch 4: Loss = 0.3302\n",
      "Epoch 5: Loss = 0.3686\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LSTMClassifier(len(word2idx), 100, 128, len(mlb.classes_), embedding_matrix).to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_x)\n",
    "        loss = criterion(output, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}: Loss = {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57730f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Evaluation Metrics:\n",
      "                 Metric     Value\n",
      "0              F1 Score  0.176237\n",
      "1             Precision  0.564499\n",
      "2                Recall  0.104418\n",
      "3  Exact Match Accuracy  0.007022\n",
      "4          Hamming Loss  0.141341\n",
      "5         Jaccard Score  0.096634\n",
      "6              Hit Rate  0.274719\n",
      "7               ROC AUC  0.763261\n",
      "\n",
      "ðŸ“Š Evaluation Metrics:\n",
      "                 Metric     Value\n",
      "0              F1 Score  0.199746\n",
      "1             Precision  0.578269\n",
      "2                Recall  0.120723\n",
      "3  Exact Match Accuracy  0.011211\n",
      "4          Hamming Loss  0.141031\n",
      "5         Jaccard Score  0.110954\n",
      "6              Hit Rate  0.316143\n",
      "7               ROC AUC  0.773717\n",
      "\n",
      "ðŸ“Š Evaluation Metrics:\n",
      "                 Metric     Value\n",
      "0              F1 Score  0.209826\n",
      "1             Precision  0.580702\n",
      "2                Recall  0.128046\n",
      "3  Exact Match Accuracy  0.014590\n",
      "4          Hamming Loss  0.139899\n",
      "5         Jaccard Score  0.117210\n",
      "6              Hit Rate  0.337823\n",
      "7               ROC AUC  0.771184\n"
     ]
    }
   ],
   "source": [
    "def predict_genres_with_lstm(model, dataloader, df_source, mlb, id2label, threshold=0.5, device='cpu'):\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in dataloader:\n",
    "            batch_x = batch_x.to(device)\n",
    "            outputs = model(batch_x)\n",
    "            all_probs.append(outputs.cpu().numpy())\n",
    "            all_labels.append(batch_y.numpy())\n",
    "\n",
    "    # Concatenate\n",
    "    probabilities = np.vstack(all_probs)\n",
    "    y_true = np.vstack(all_labels)\n",
    "\n",
    "    # Apply threshold\n",
    "    predictions = (probabilities >= threshold).astype(int)\n",
    "\n",
    "    # Decode predicted genres using id2label\n",
    "    predicted_genres = []\n",
    "    for row in predictions:\n",
    "        genres = [id2label[i] for i, val in enumerate(row) if val == 1]\n",
    "        predicted_genres.append(genres)\n",
    "\n",
    "    # === Calculate metrics ===\n",
    "    from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, hamming_loss, jaccard_score, roc_auc_score\n",
    "\n",
    "    f1 = f1_score(y_true, predictions, average='micro')\n",
    "    precision = precision_score(y_true, predictions, average='micro')\n",
    "    recall = recall_score(y_true, predictions, average='micro')\n",
    "    accuracy = accuracy_score(y_true, predictions)\n",
    "    hamming = hamming_loss(y_true, predictions)\n",
    "    jaccard = jaccard_score(y_true, predictions, average='micro')\n",
    "    hit_rate = (np.logical_and(y_true, predictions).sum(axis=1) > 0).mean()\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(y_true, probabilities, average='micro')\n",
    "    except ValueError:\n",
    "        roc_auc = np.nan\n",
    "\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Metric': [\n",
    "            'F1 Score', 'Precision', 'Recall', 'Exact Match Accuracy',\n",
    "            'Hamming Loss', 'Jaccard Score', 'Hit Rate', 'ROC AUC'\n",
    "        ],\n",
    "        'Value': [\n",
    "            f1, precision, recall, accuracy,\n",
    "            hamming, jaccard, hit_rate, roc_auc\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    result_df = pd.DataFrame({\n",
    "        \"synopsis\": df_source[\"synopsis\"].values,\n",
    "        \"true_genres\": df_source[\"genres\"].values,\n",
    "        \"predicted_genres\": predicted_genres\n",
    "    })\n",
    "\n",
    "    print(\"\\nðŸ“Š Evaluation Metrics:\")\n",
    "    print(metrics_df)\n",
    "\n",
    "    return result_df, metrics_df, probabilities, y_true, predictions\n",
    "\n",
    "use_thresh = 0.5\n",
    "id2label = {i: label for i, label in enumerate(mlb.classes_)}\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "df_train_results, train_metrics, train_prob, train_labels, train_pred = predict_genres_with_lstm(\n",
    "    model, train_loader, df_train, mlb, id2label, threshold=use_thresh, device=device)\n",
    "\n",
    "df_val_results, val_metrics, val_prob, val_labels, val_pred = predict_genres_with_lstm(\n",
    "    model, val_loader, df_val, mlb, id2label, threshold=use_thresh, device=device)\n",
    "\n",
    "df_test_results, test_metrics, test_prob, test_labels, test_pred = predict_genres_with_lstm(\n",
    "    model, test_loader, df_test, mlb, id2label, threshold=use_thresh, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c397119b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m display(\u001b[43mdf_train_results\u001b[49m)\n\u001b[0;32m      2\u001b[0m display(df_val_results)\n\u001b[0;32m      3\u001b[0m display(df_test_results)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_train_results' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
